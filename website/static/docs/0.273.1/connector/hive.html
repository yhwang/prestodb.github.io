
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="374665">
  <script src="../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-82811140-44"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'UA-82811140-44');
</script>
  
  
    <title>Hive Connector &#8212; Presto 0.273.1 Documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/presto.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Hive Security Configuration" href="hive-security.html" />
    <link rel="prev" title="Elasticsearch Connector" href="elasticsearch.html" />
  
   

  </head>
  <body dir=ltr
        data-md-color-primary=grey data-md-color-accent=blue>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#connector/hive" tabindex="1" class="md-skip"> Skip to content </a>
  <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="../index.html" title="Presto 0.273.1 Documentation"
           class="md-header-nav__button md-logo">
          
              <img src="../_static/logo.png" height="26"
                   alt="Presto 0.273.1 Documentation logo">
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <span class="md-header-nav__topic">Presto 0.273.1 Documentation</span>
          <span class="md-header-nav__topic"> Hive Connector </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" action="../search.html" method="get" name="search">
      <input type="text" class="md-search__input" name="q" placeholder="Search"
             autocapitalize="off" autocomplete="off" spellcheck="false"
             data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>

      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            <a href="https://github.com/prestodb/presto" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Presto
  </div>
</a>
          </div>
        </div>
      
      
  
  <script src="../_static/javascripts/version_dropdown.js"></script>
  <script>
    var json_loc = "../"versions.json"",
        target_loc = "../../",
        text = "Versions";
    $( document ).ready( add_version_dropdown(json_loc, target_loc, text));
  </script>
  

    </div>
  </nav>
</header>

  
  <div class="md-container">
    
    
    <!-- empty -->
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="Presto 0.273.1 Documentation" class="md-nav__button md-logo">
      
        <img src="../_static/logo.png" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../index.html"
       title="Presto 0.273.1 Documentation">Presto 0.273.1 Documentation</a>
  </label>
    <div class="md-nav__source">
      <a href="https://github.com/prestodb/presto" title="Go to repository" class="md-source" data-md-source="github">

    <div class="md-source__icon">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 24 24" width="28" height="28">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    Presto
  </div>
</a>
    </div>
  
  

  
  <ul class="md-nav__list">
    <li class="md-nav__item">
    
    
      <a href="../overview.html" class="md-nav__link">Overview</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../installation.html" class="md-nav__link">Installation</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../security.html" class="md-nav__link">Security</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../admin.html" class="md-nav__link">Administration</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../cache.html" class="md-nav__link">Cache</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../optimizer.html" class="md-nav__link">Query Optimizer</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../connector.html" class="md-nav__link">Connectors</a>
      <ul class="md-nav__list"> 
    <li class="md-nav__item">
    
    
      <a href="accumulo.html" class="md-nav__link">Accumulo Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="bigquery.html" class="md-nav__link">BigQuery Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="blackhole.html" class="md-nav__link">Black Hole Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="cassandra.html" class="md-nav__link">Cassandra Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="deltalake.html" class="md-nav__link">Delta Lake Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="druid.html" class="md-nav__link">Druid Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="elasticsearch.html" class="md-nav__link">Elasticsearch Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    <label class="md-nav__link md-nav__link--active" for="__toc"> Hive Connector </label>
    
      <a href="#" class="md-nav__link md-nav__link--active">Hive Connector</a>
      
        
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#connector-hive--page-root" class="md-nav__link">Hive Connector</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#overview" class="md-nav__link">Overview</a>
        </li>
        <li class="md-nav__item"><a href="#supported-file-types" class="md-nav__link">Supported File Types</a>
        </li>
        <li class="md-nav__item"><a href="#configuration" class="md-nav__link">Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#multiple-hive-clusters" class="md-nav__link">Multiple Hive Clusters</a>
        </li>
        <li class="md-nav__item"><a href="#hdfs-configuration" class="md-nav__link">HDFS Configuration</a>
        </li>
        <li class="md-nav__item"><a href="#hdfs-username" class="md-nav__link">HDFS Username</a>
        </li>
        <li class="md-nav__item"><a href="#accessing-hadoop-clusters-protected-with-kerberos-authentication" class="md-nav__link">Accessing Hadoop clusters protected with Kerberos authentication</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#hive-configuration-properties" class="md-nav__link">Hive Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#metastore-configuration-properties" class="md-nav__link">Metastore Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#aws-glue-catalog-configuration-properties" class="md-nav__link">AWS Glue Catalog Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#amazon-s3-configuration" class="md-nav__link">Amazon S3 Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#s3-configuration-properties" class="md-nav__link">S3 Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#s3-credentials" class="md-nav__link">S3 Credentials</a>
        </li>
        <li class="md-nav__item"><a href="#custom-s3-credentials-provider" class="md-nav__link">Custom S3 Credentials Provider</a>
        </li>
        <li class="md-nav__item"><a href="#tuning-properties" class="md-nav__link">Tuning Properties</a>
        </li>
        <li class="md-nav__item"><a href="#s3-data-encryption" class="md-nav__link">S3 Data Encryption</a>
        </li>
        <li class="md-nav__item"><a href="#id1" class="md-nav__link">S3SelectPushdown</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#is-s3-select-a-good-fit-for-my-workload" class="md-nav__link">Is S3 Select a good fit for my workload?</a>
        </li>
        <li class="md-nav__item"><a href="#considerations-and-limitations" class="md-nav__link">Considerations and Limitations</a>
        </li>
        <li class="md-nav__item"><a href="#enabling-s3-select-pushdown" class="md-nav__link">Enabling S3 Select Pushdown</a>
        </li>
        <li class="md-nav__item"><a href="#understanding-and-tuning-the-maximum-connections" class="md-nav__link">Understanding and Tuning the Maximum Connections</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#alluxio-configuration" class="md-nav__link">Alluxio Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#alluxio-client-side-configuration" class="md-nav__link">Alluxio Client-Side Configuration</a>
        </li>
        <li class="md-nav__item"><a href="#deploy-alluxio-with-presto" class="md-nav__link">Deploy Alluxio with Presto</a>
        </li>
        <li class="md-nav__item"><a href="#alluxio-catalog-service" class="md-nav__link">Alluxio Catalog Service</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#table-statistics" class="md-nav__link">Table Statistics</a>
        </li>
        <li class="md-nav__item"><a href="#collecting-table-and-column-statistics" class="md-nav__link">Collecting table and column statistics</a>
        </li>
        <li class="md-nav__item"><a href="#schema-evolution" class="md-nav__link">Schema Evolution</a>
        </li>
        <li class="md-nav__item"><a href="#avro-schema-evolution" class="md-nav__link">Avro Schema Evolution</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#limitations" class="md-nav__link">Limitations</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#procedures" class="md-nav__link">Procedures</a>
        </li>
        <li class="md-nav__item"><a href="#extra-hidden-columns" class="md-nav__link">Extra Hidden Columns</a>
        </li>
        <li class="md-nav__item"><a href="#examples" class="md-nav__link">Examples</a>
        </li>
        <li class="md-nav__item"><a href="#hive-connector-limitations" class="md-nav__link">Hive Connector Limitations</a>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="hive-security.html" class="md-nav__link">Hive Security Configuration</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="iceberg.html" class="md-nav__link">Iceberg Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="jmx.html" class="md-nav__link">JMX Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="kafka.html" class="md-nav__link">Kafka Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="kafka-tutorial.html" class="md-nav__link">Kafka Connector Tutorial</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="kudu.html" class="md-nav__link">Kudu Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="larksheets.html" class="md-nav__link">Lark Sheets connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="localfile.html" class="md-nav__link">Local File Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="memory.html" class="md-nav__link">Memory Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="mongodb.html" class="md-nav__link">MongoDB Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="mysql.html" class="md-nav__link">MySQL Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="oracle.html" class="md-nav__link">Oracle Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="pinot.html" class="md-nav__link">Apache Pinot Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="postgresql.html" class="md-nav__link">PostgreSQL Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="prometheus.html" class="md-nav__link">Prometheus Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="redis.html" class="md-nav__link">Redis Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="redshift.html" class="md-nav__link">Redshift Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="sqlserver.html" class="md-nav__link">SQL Server Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="system.html" class="md-nav__link">System Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="thrift.html" class="md-nav__link">Thrift Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="tpcds.html" class="md-nav__link">TPCDS Connector</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="tpch.html" class="md-nav__link">TPCH Connector</a>
      
    
    </li></ul>
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../functions.html" class="md-nav__link">Functions and Operators</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../language.html" class="md-nav__link">SQL Language</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../sql.html" class="md-nav__link">SQL Statement Syntax</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../migration.html" class="md-nav__link">Migration</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../develop.html" class="md-nav__link">Developer Guide</a>
      
    
    </li>
    <li class="md-nav__item">
    
    
      <a href="../release.html" class="md-nav__link">Release Notes</a>
      
    
    </li>
  </ul>
  

</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">Contents</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#connector-hive--page-root" class="md-nav__link">Hive Connector</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#overview" class="md-nav__link">Overview</a>
        </li>
        <li class="md-nav__item"><a href="#supported-file-types" class="md-nav__link">Supported File Types</a>
        </li>
        <li class="md-nav__item"><a href="#configuration" class="md-nav__link">Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#multiple-hive-clusters" class="md-nav__link">Multiple Hive Clusters</a>
        </li>
        <li class="md-nav__item"><a href="#hdfs-configuration" class="md-nav__link">HDFS Configuration</a>
        </li>
        <li class="md-nav__item"><a href="#hdfs-username" class="md-nav__link">HDFS Username</a>
        </li>
        <li class="md-nav__item"><a href="#accessing-hadoop-clusters-protected-with-kerberos-authentication" class="md-nav__link">Accessing Hadoop clusters protected with Kerberos authentication</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#hive-configuration-properties" class="md-nav__link">Hive Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#metastore-configuration-properties" class="md-nav__link">Metastore Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#aws-glue-catalog-configuration-properties" class="md-nav__link">AWS Glue Catalog Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#amazon-s3-configuration" class="md-nav__link">Amazon S3 Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#s3-configuration-properties" class="md-nav__link">S3 Configuration Properties</a>
        </li>
        <li class="md-nav__item"><a href="#s3-credentials" class="md-nav__link">S3 Credentials</a>
        </li>
        <li class="md-nav__item"><a href="#custom-s3-credentials-provider" class="md-nav__link">Custom S3 Credentials Provider</a>
        </li>
        <li class="md-nav__item"><a href="#tuning-properties" class="md-nav__link">Tuning Properties</a>
        </li>
        <li class="md-nav__item"><a href="#s3-data-encryption" class="md-nav__link">S3 Data Encryption</a>
        </li>
        <li class="md-nav__item"><a href="#id1" class="md-nav__link">S3SelectPushdown</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#is-s3-select-a-good-fit-for-my-workload" class="md-nav__link">Is S3 Select a good fit for my workload?</a>
        </li>
        <li class="md-nav__item"><a href="#considerations-and-limitations" class="md-nav__link">Considerations and Limitations</a>
        </li>
        <li class="md-nav__item"><a href="#enabling-s3-select-pushdown" class="md-nav__link">Enabling S3 Select Pushdown</a>
        </li>
        <li class="md-nav__item"><a href="#understanding-and-tuning-the-maximum-connections" class="md-nav__link">Understanding and Tuning the Maximum Connections</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#alluxio-configuration" class="md-nav__link">Alluxio Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#alluxio-client-side-configuration" class="md-nav__link">Alluxio Client-Side Configuration</a>
        </li>
        <li class="md-nav__item"><a href="#deploy-alluxio-with-presto" class="md-nav__link">Deploy Alluxio with Presto</a>
        </li>
        <li class="md-nav__item"><a href="#alluxio-catalog-service" class="md-nav__link">Alluxio Catalog Service</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#table-statistics" class="md-nav__link">Table Statistics</a>
        </li>
        <li class="md-nav__item"><a href="#collecting-table-and-column-statistics" class="md-nav__link">Collecting table and column statistics</a>
        </li>
        <li class="md-nav__item"><a href="#schema-evolution" class="md-nav__link">Schema Evolution</a>
        </li>
        <li class="md-nav__item"><a href="#avro-schema-evolution" class="md-nav__link">Avro Schema Evolution</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#limitations" class="md-nav__link">Limitations</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#procedures" class="md-nav__link">Procedures</a>
        </li>
        <li class="md-nav__item"><a href="#extra-hidden-columns" class="md-nav__link">Extra Hidden Columns</a>
        </li>
        <li class="md-nav__item"><a href="#examples" class="md-nav__link">Examples</a>
        </li>
        <li class="md-nav__item"><a href="#hive-connector-limitations" class="md-nav__link">Hive Connector Limitations</a>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <section id="hive-connector">
<h1 id="connector-hive--page-root">Hive Connector<a class="headerlink" href="#connector-hive--page-root" title="Permalink to this headline">#</a></h1>
<div class="contents local topic" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#overview" id="id3">Overview</a></p></li>
<li><p><a class="reference internal" href="#supported-file-types" id="id4">Supported File Types</a></p></li>
<li><p><a class="reference internal" href="#configuration" id="id5">Configuration</a></p></li>
<li><p><a class="reference internal" href="#hive-configuration-properties" id="id6">Hive Configuration Properties</a></p></li>
<li><p><a class="reference internal" href="#metastore-configuration-properties" id="id7">Metastore Configuration Properties</a></p></li>
<li><p><a class="reference internal" href="#aws-glue-catalog-configuration-properties" id="id8">AWS Glue Catalog Configuration Properties</a></p></li>
<li><p><a class="reference internal" href="#amazon-s3-configuration" id="id9">Amazon S3 Configuration</a></p></li>
<li><p><a class="reference internal" href="#alluxio-configuration" id="id10">Alluxio Configuration</a></p></li>
<li><p><a class="reference internal" href="#table-statistics" id="id11">Table Statistics</a></p></li>
<li><p><a class="reference internal" href="#collecting-table-and-column-statistics" id="id12">Collecting table and column statistics</a></p></li>
<li><p><a class="reference internal" href="#schema-evolution" id="id13">Schema Evolution</a></p></li>
<li><p><a class="reference internal" href="#avro-schema-evolution" id="id14">Avro Schema Evolution</a></p></li>
<li><p><a class="reference internal" href="#procedures" id="id15">Procedures</a></p></li>
<li><p><a class="reference internal" href="#extra-hidden-columns" id="id16">Extra Hidden Columns</a></p></li>
<li><p><a class="reference internal" href="#examples" id="id17">Examples</a></p></li>
<li><p><a class="reference internal" href="#hive-connector-limitations" id="id18">Hive Connector Limitations</a></p></li>
</ul>
</div>
<section id="overview">
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permalink to this headline">#</a></h2>
<p>The Hive connector allows querying data stored in a Hive
data warehouse. Hive is a combination of three components:</p>
<ul class="simple">
<li><p>Data files in varying formats that are typically stored in the
Hadoop Distributed File System (HDFS) or in Amazon S3.</p></li>
<li><p>Metadata about how the data files are mapped to schemas and tables.
This metadata is stored in a database such as MySQL and is accessed
via the Hive metastore service.</p></li>
<li><p>A query language called HiveQL. This query language is executed
on a distributed computing framework such as MapReduce or Tez.</p></li>
</ul>
<p>Presto only uses the first two components: the data and the metadata.
It does not use HiveQL or any part of Hive’s execution environment.</p>
</section>
<section id="supported-file-types">
<h2 id="supported-file-types">Supported File Types<a class="headerlink" href="#supported-file-types" title="Permalink to this headline">#</a></h2>
<p>The following file types are supported for the Hive connector:</p>
<ul class="simple">
<li><p>ORC</p></li>
<li><p>Parquet</p></li>
<li><p>Avro</p></li>
<li><p>RCFile</p></li>
<li><p>SequenceFile</p></li>
<li><p>JSON</p></li>
<li><p>Text</p></li>
</ul>
</section>
<section id="configuration">
<h2 id="configuration">Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">#</a></h2>
<p>The Hive connector supports Apache Hadoop 2.x and derivative distributions
including Cloudera CDH 5 and Hortonworks Data Platform (HDP).</p>
<p>Create <code class="docutils literal notranslate"><span class="pre">etc/catalog/hive.properties</span></code> with the following contents
to mount the <code class="docutils literal notranslate"><span class="pre">hive-hadoop2</span></code> connector as the <code class="docutils literal notranslate"><span class="pre">hive</span></code> catalog,
replacing <code class="docutils literal notranslate"><span class="pre">example.net:9083</span></code> with the correct host and port
for your Hive metastore Thrift service:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>connector.name=hive-hadoop2
hive.metastore.uri=thrift://example.net:9083
</pre></div>
</div>
<section id="multiple-hive-clusters">
<h3 id="multiple-hive-clusters">Multiple Hive Clusters<a class="headerlink" href="#multiple-hive-clusters" title="Permalink to this headline">#</a></h3>
<p>You can have as many catalogs as you need, so if you have additional
Hive clusters, simply add another properties file to <code class="docutils literal notranslate"><span class="pre">etc/catalog</span></code>
with a different name (making sure it ends in <code class="docutils literal notranslate"><span class="pre">.properties</span></code>). For
example, if you name the property file <code class="docutils literal notranslate"><span class="pre">sales.properties</span></code>, Presto
will create a catalog named <code class="docutils literal notranslate"><span class="pre">sales</span></code> using the configured connector.</p>
</section>
<section id="hdfs-configuration">
<h3 id="hdfs-configuration">HDFS Configuration<a class="headerlink" href="#hdfs-configuration" title="Permalink to this headline">#</a></h3>
<p>For basic setups, Presto configures the HDFS client automatically and
does not require any configuration files. In some cases, such as when using
federated HDFS or NameNode high availability, it is necessary to specify
additional HDFS client options in order to access your HDFS cluster. To do so,
add the <code class="docutils literal notranslate"><span class="pre">hive.config.resources</span></code> property to reference your HDFS config files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
</pre></div>
</div>
<p>Only specify additional configuration files if necessary for your setup.
We also recommend reducing the configuration files to have the minimum
set of required properties, as additional properties may cause problems.</p>
<p>The configuration files must exist on all Presto nodes. If you are
referencing existing Hadoop config files, make sure to copy them to
any Presto nodes that are not running Hadoop.</p>
</section>
<section id="hdfs-username">
<h3 id="hdfs-username">HDFS Username<a class="headerlink" href="#hdfs-username" title="Permalink to this headline">#</a></h3>
<p>When not using Kerberos with HDFS, Presto will access HDFS using the
OS user of the Presto process. For example, if Presto is running as
<code class="docutils literal notranslate"><span class="pre">nobody</span></code>, it will access HDFS as <code class="docutils literal notranslate"><span class="pre">nobody</span></code>. You can override this
username by setting the <code class="docutils literal notranslate"><span class="pre">HADOOP_USER_NAME</span></code> system property in the
Presto <a class="reference internal" href="../installation/deployment.html#presto-jvm-config"><span class="std std-ref">JVM Config</span></a>, replacing <code class="docutils literal notranslate"><span class="pre">hdfs_user</span></code> with the
appropriate username:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-DHADOOP_USER_NAME=hdfs_user
</pre></div>
</div>
</section>
<section id="accessing-hadoop-clusters-protected-with-kerberos-authentication">
<h3 id="accessing-hadoop-clusters-protected-with-kerberos-authentication">Accessing Hadoop clusters protected with Kerberos authentication<a class="headerlink" href="#accessing-hadoop-clusters-protected-with-kerberos-authentication" title="Permalink to this headline">#</a></h3>
<p>Kerberos authentication is supported for both HDFS and the Hive metastore.
However, Kerberos authentication by ticket cache is not yet supported.</p>
<p>The properties that apply to Hive connector security are listed in the
<a class="reference internal" href="#hive-configuration-properties">Hive Configuration Properties</a> table. Please see the
<a class="reference internal" href="hive-security.html"><span class="doc">Hive Security Configuration</span></a> section for a more detailed discussion of the
security options in the Hive connector.</p>
</section>
</section>
<section id="hive-configuration-properties">
<h2 id="hive-configuration-properties">Hive Configuration Properties<a class="headerlink" href="#hive-configuration-properties" title="Permalink to this headline">#</a></h2>
<table>
<colgroup>
<col style="width: 41%"/>
<col style="width: 49%"/>
<col style="width: 10%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.uri</span></code></p></td>
<td><p>The URI(s) of the Hive metastore to connect to using the
Thrift protocol. If multiple URIs are provided, the first
URI is used by default and the rest of the URIs are
fallback metastores. This property is required.
Example: <code class="docutils literal notranslate"><span class="pre">thrift://192.0.2.3:9083</span></code> or
<code class="docutils literal notranslate"><span class="pre">thrift://192.0.2.3:9083,thrift://192.0.2.4:9083</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.username</span></code></p></td>
<td><p>The username Presto will use to access the Hive metastore.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.config.resources</span></code></p></td>
<td><p>An optional comma-separated list of HDFS
configuration files. These files must exist on the
machines running Presto. Only specify this if
absolutely necessary to access HDFS.
Example: <code class="docutils literal notranslate"><span class="pre">/etc/hdfs-site.xml</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.storage-format</span></code></p></td>
<td><p>The default file format used when creating new tables.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ORC</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.compression-codec</span></code></p></td>
<td><p>The compression codec to use when writing files.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GZIP</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.force-local-scheduling</span></code></p></td>
<td><p>Force splits to be scheduled on the same node as the Hadoop
DataNode process serving the split data.  This is useful for
installations where Presto is collocated with every
DataNode.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.order-based-execution-enabled</span></code></p></td>
<td><p>Enable order-based execution. When it’s enabled, hive files
become non-splittable and the table ordering properties
would be exposed to plan optimizer</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.respect-table-format</span></code></p></td>
<td><p>Should new partitions be written using the existing table
format or the default Presto format?</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.immutable-partitions</span></code></p></td>
<td><p>Can new data be inserted into existing partitions?</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.create-empty-bucket-files</span></code></p></td>
<td><p>Should empty files be created for buckets that have no data?</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.max-partitions-per-writers</span></code></p></td>
<td><p>Maximum number of partitions per writer.</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.max-partitions-per-scan</span></code></p></td>
<td><p>Maximum number of partitions for a single table scan.</p></td>
<td><p>100,000</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.authentication.type</span></code></p></td>
<td><p>Hive metastore authentication type.
Possible values are <code class="docutils literal notranslate"><span class="pre">NONE</span></code> or <code class="docutils literal notranslate"><span class="pre">KERBEROS</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">NONE</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.service.principal</span></code></p></td>
<td><p>The Kerberos principal of the Hive metastore service.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.client.principal</span></code></p></td>
<td><p>The Kerberos principal that Presto will use when connecting
to the Hive metastore service.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.client.keytab</span></code></p></td>
<td><p>Hive metastore client keytab location.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.authentication.type</span></code></p></td>
<td><p>HDFS authentication type.
Possible values are <code class="docutils literal notranslate"><span class="pre">NONE</span></code> or <code class="docutils literal notranslate"><span class="pre">KERBEROS</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">NONE</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.impersonation.enabled</span></code></p></td>
<td><p>Enable HDFS end user impersonation.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.presto.principal</span></code></p></td>
<td><p>The Kerberos principal that Presto will use when connecting
to HDFS.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.presto.keytab</span></code></p></td>
<td><p>HDFS client keytab location.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.security</span></code></p></td>
<td><p>See <a class="reference internal" href="hive-security.html"><span class="doc">Hive Security Configuration</span></a>.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">security.config-file</span></code></p></td>
<td><p>Path of config file to use when <code class="docutils literal notranslate"><span class="pre">hive.security=file</span></code>.
See <a class="reference internal" href="hive-security.html#hive-file-based-authorization"><span class="std std-ref">File Based Authorization</span></a> for details.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.non-managed-table-writes-enabled</span></code></p></td>
<td><p>Enable writes to non-managed (external) Hive tables.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.non-managed-table-creates-enabled</span></code></p></td>
<td><p>Enable creating non-managed (external) Hive tables.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.collect-column-statistics-on-write</span></code></p></td>
<td><p>Enables automatic column level statistics collection
on write. See <a class="reference external" href="#table-statistics">Table Statistics</a> for
details.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3select-pushdown.enabled</span></code></p></td>
<td><p>Enable query pushdown to AWS S3 Select service.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3select-pushdown.max-connections</span></code></p></td>
<td><p>Maximum number of simultaneously open connections to S3 for
S3SelectPushdown.</p></td>
<td><p>500</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.load-balancing-enabled</span></code></p></td>
<td><p>Enable load balancing between multiple Metastore instances</p></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="metastore-configuration-properties">
<h2 id="metastore-configuration-properties">Metastore Configuration Properties<a class="headerlink" href="#metastore-configuration-properties" title="Permalink to this headline">#</a></h2>
<p>The required Hive metastore can be configured with a number of properties.</p>
<table>
<colgroup>
<col style="width: 35%"/>
<col style="width: 54%"/>
<col style="width: 11%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-timeout</span></code></p></td>
<td><p>Timeout for Hive metastore requests.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">10s</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-cache-ttl</span></code></p></td>
<td><p>Duration how long cached metastore data should be considered
valid.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0s</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-cache-maximum-size</span></code></p></td>
<td><p>Hive metastore cache maximum size.</p></td>
<td><p>10000</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-refresh-interval</span></code></p></td>
<td><p>Asynchronously refresh cached metastore data after access
if it is older than this but is not yet expired, allowing
subsequent accesses to see fresh data.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0s</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-refresh-max-threads</span></code></p></td>
<td><p>Maximum threads used to refresh cached metastore data.</p></td>
<td><p>100</p></td>
</tr>
</tbody>
</table>
</section>
<section id="aws-glue-catalog-configuration-properties">
<h2 id="aws-glue-catalog-configuration-properties">AWS Glue Catalog Configuration Properties<a class="headerlink" href="#aws-glue-catalog-configuration-properties" title="Permalink to this headline">#</a></h2>
<table>
<colgroup>
<col style="width: 46%"/>
<col style="width: 54%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.region</span></code></p></td>
<td><p>AWS region of the Glue Catalog. This is required when not
running in EC2, or when the catalog is in a different region.
Example: <code class="docutils literal notranslate"><span class="pre">us-east-1</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.pin-client-to-current-region</span></code></p></td>
<td><p>Pin Glue requests to the same region as the EC2 instance
where Presto is running (defaults to <code class="docutils literal notranslate"><span class="pre">false</span></code>).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.max-connections</span></code></p></td>
<td><p>Max number of concurrent connections to Glue
(defaults to <code class="docutils literal notranslate"><span class="pre">5</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.max-error-retries</span></code></p></td>
<td><p>Maximum number of error retries for the Glue client,
defaults to <code class="docutils literal notranslate"><span class="pre">10</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.default-warehouse-dir</span></code></p></td>
<td><p>Hive Glue metastore default warehouse directory</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-access-key</span></code></p></td>
<td><p>AWS access key to use to connect to the Glue Catalog. If
specified along with <code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-secret-key</span></code>,
this parameter takes precedence over
<code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.iam-role</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-secret-key</span></code></p></td>
<td><p>AWS secret key to use to connect to the Glue Catalog. If
specified along with <code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-access-key</span></code>,
this parameter takes precedence over
<code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.iam-role</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.catalogid</span></code></p></td>
<td><p>The ID of the Glue Catalog in which the metadata database
resides.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.endpoint-url</span></code></p></td>
<td><p>Glue API endpoint URL (optional).
Example: <code class="docutils literal notranslate"><span class="pre">https://glue.us-east-1.amazonaws.com</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.partitions-segments</span></code></p></td>
<td><p>Number of segments for partitioned Glue tables.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.get-partition-threads</span></code></p></td>
<td><p>Number of threads for parallel partition fetches from Glue.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.iam-role</span></code></p></td>
<td><p>ARN of an IAM role to assume when connecting to the Glue
Catalog.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="amazon-s3-configuration">
<span id="s3selectpushdown"></span><h2 id="amazon-s3-configuration">Amazon S3 Configuration<a class="headerlink" href="#amazon-s3-configuration" title="Permalink to this headline">#</a></h2>
<p>The Hive Connector can read and write tables that are stored in S3.
This is accomplished by having a table or database location that
uses an S3 prefix rather than an HDFS prefix.</p>
<p>Presto uses its own S3 filesystem for the URI prefixes
<code class="docutils literal notranslate"><span class="pre">s3://</span></code>, <code class="docutils literal notranslate"><span class="pre">s3n://</span></code> and  <code class="docutils literal notranslate"><span class="pre">s3a://</span></code>.</p>
<section id="s3-configuration-properties">
<h3 id="s3-configuration-properties">S3 Configuration Properties<a class="headerlink" href="#s3-configuration-properties" title="Permalink to this headline">#</a></h3>
<table>
<colgroup>
<col style="width: 35%"/>
<col style="width: 65%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.use-instance-credentials</span></code></p></td>
<td><p>Use the EC2 metadata service to retrieve API credentials
(defaults to <code class="docutils literal notranslate"><span class="pre">true</span></code>). This works with IAM roles in EC2.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.aws-access-key</span></code></p></td>
<td><p>Default AWS access key to use.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.aws-secret-key</span></code></p></td>
<td><p>Default AWS secret key to use.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.iam-role</span></code></p></td>
<td><p>IAM role to assume.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.endpoint</span></code></p></td>
<td><p>The S3 storage endpoint server. This can be used to
connect to an S3-compatible storage system instead
of AWS. When using v4 signatures, it is recommended to
set this to the AWS region-specific endpoint
(e.g., <code class="docutils literal notranslate"><span class="pre">http[s]://&lt;bucket&gt;.s3-&lt;AWS-region&gt;.amazonaws.com</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.storage-class</span></code></p></td>
<td><p>The S3 storage class to use when writing the data. Currently only
<code class="docutils literal notranslate"><span class="pre">STANDARD</span></code> and <code class="docutils literal notranslate"><span class="pre">INTELLIGENT_TIERING</span></code> storage classes are supported.
Default storage class is <code class="docutils literal notranslate"><span class="pre">STANDARD</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.signer-type</span></code></p></td>
<td><p>Specify a different signer type for S3-compatible storage.
Example: <code class="docutils literal notranslate"><span class="pre">S3SignerType</span></code> for v2 signer type</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.path-style-access</span></code></p></td>
<td><p>Use path-style access for all requests to the S3-compatible storage.
This is for S3-compatible storage that doesn’t support virtual-hosted-style access.
(defaults to <code class="docutils literal notranslate"><span class="pre">false</span></code>)</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.staging-directory</span></code></p></td>
<td><p>Local staging directory for data written to S3.
This defaults to the Java temporary directory specified
by the JVM system property <code class="docutils literal notranslate"><span class="pre">java.io.tmpdir</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.pin-client-to-current-region</span></code></p></td>
<td><p>Pin S3 requests to the same region as the EC2
instance where Presto is running (defaults to <code class="docutils literal notranslate"><span class="pre">false</span></code>).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.ssl.enabled</span></code></p></td>
<td><p>Use HTTPS to communicate with the S3 API (defaults to <code class="docutils literal notranslate"><span class="pre">true</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.sse.enabled</span></code></p></td>
<td><p>Use S3 server-side encryption (defaults to <code class="docutils literal notranslate"><span class="pre">false</span></code>).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.sse.type</span></code></p></td>
<td><p>The type of key management for S3 server-side encryption.
Use <code class="docutils literal notranslate"><span class="pre">S3</span></code> for S3 managed or <code class="docutils literal notranslate"><span class="pre">KMS</span></code> for KMS-managed keys
(defaults to <code class="docutils literal notranslate"><span class="pre">S3</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.sse.kms-key-id</span></code></p></td>
<td><p>The KMS Key ID to use for S3 server-side encryption with
KMS-managed keys. If not set, the default key is used.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.kms-key-id</span></code></p></td>
<td><p>If set, use S3 client-side encryption and use the AWS
KMS to store encryption keys and use the value of
this property as the KMS Key ID for newly created
objects.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.encryption-materials-provider</span></code></p></td>
<td><p>If set, use S3 client-side encryption and use the
value of this property as the fully qualified name of
a Java class which implements the AWS SDK’s
<code class="docutils literal notranslate"><span class="pre">EncryptionMaterialsProvider</span></code> interface.   If the
class also implements <code class="docutils literal notranslate"><span class="pre">Configurable</span></code> from the Hadoop
API, the Hadoop configuration will be passed in after
the object has been created.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.upload-acl-type</span></code></p></td>
<td><p>Canned ACL to use while uploading files to S3 (defaults
to <code class="docutils literal notranslate"><span class="pre">Private</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.skip-glacier-objects</span></code></p></td>
<td><p>Ignore Glacier objects rather than failing the query. This
will skip data that may be expected to be part of the table
or partition. Defaults to <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="s3-credentials">
<h3 id="s3-credentials">S3 Credentials<a class="headerlink" href="#s3-credentials" title="Permalink to this headline">#</a></h3>
<p>If you are running Presto on Amazon EC2 using EMR or another facility,
it is highly recommended that you set <code class="docutils literal notranslate"><span class="pre">hive.s3.use-instance-credentials</span></code>
to <code class="docutils literal notranslate"><span class="pre">true</span></code> and use IAM Roles for EC2 to govern access to S3. If this is
the case, your EC2 instances will need to be assigned an IAM Role which
grants appropriate access to the data stored in the S3 bucket(s) you wish
to use. It’s also possible to configure an IAM role with <code class="docutils literal notranslate"><span class="pre">hive.s3.iam-role</span></code>
that will be assumed for accessing any S3 bucket. This is much cleaner than
setting AWS access and secret keys in the <code class="docutils literal notranslate"><span class="pre">hive.s3.aws-access-key</span></code>
and <code class="docutils literal notranslate"><span class="pre">hive.s3.aws-secret-key</span></code> settings, and also allows EC2 to automatically
rotate credentials on a regular basis without any additional work on your part.</p>
</section>
<section id="custom-s3-credentials-provider">
<h3 id="custom-s3-credentials-provider">Custom S3 Credentials Provider<a class="headerlink" href="#custom-s3-credentials-provider" title="Permalink to this headline">#</a></h3>
<p>You can configure a custom S3 credentials provider by setting the Hadoop
configuration property <code class="docutils literal notranslate"><span class="pre">presto.s3.credentials-provider</span></code> to be the
fully qualified class name of a custom AWS credentials provider
implementation. This class must implement the
<a class="reference external" href="http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/AWSCredentialsProvider.html">AWSCredentialsProvider</a>
interface and provide a two-argument constructor that takes a
<code class="docutils literal notranslate"><span class="pre">java.net.URI</span></code> and a Hadoop <code class="docutils literal notranslate"><span class="pre">org.apache.hadoop.conf.Configuration</span></code>
as arguments. A custom credentials provider can be used to provide
temporary credentials from STS (using <code class="docutils literal notranslate"><span class="pre">STSSessionCredentialsProvider</span></code>),
IAM role-based credentials (using <code class="docutils literal notranslate"><span class="pre">STSAssumeRoleSessionCredentialsProvider</span></code>),
or credentials for a specific use case (e.g., bucket/user specific credentials).
This Hadoop configuration property must be set in the Hadoop configuration
files referenced by the <code class="docutils literal notranslate"><span class="pre">hive.config.resources</span></code> Hive connector property.</p>
</section>
<section id="tuning-properties">
<h3 id="tuning-properties">Tuning Properties<a class="headerlink" href="#tuning-properties" title="Permalink to this headline">#</a></h3>
<p>The following tuning properties affect the behavior of the client
used by the Presto S3 filesystem when communicating with S3.
Most of these parameters affect settings on the <code class="docutils literal notranslate"><span class="pre">ClientConfiguration</span></code>
object associated with the <code class="docutils literal notranslate"><span class="pre">AmazonS3Client</span></code>.</p>
<table>
<colgroup>
<col style="width: 33%"/>
<col style="width: 53%"/>
<col style="width: 14%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.max-error-retries</span></code></p></td>
<td><p>Maximum number of error retries, set on the S3 client.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">10</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.max-client-retries</span></code></p></td>
<td><p>Maximum number of read attempts to retry.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">5</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.max-backoff-time</span></code></p></td>
<td><p>Use exponential backoff starting at 1 second up to
this maximum value when communicating with S3.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">10</span> <span class="pre">minutes</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.max-retry-time</span></code></p></td>
<td><p>Maximum time to retry communicating with S3.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">10</span> <span class="pre">minutes</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.connect-timeout</span></code></p></td>
<td><p>TCP connect timeout.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">5</span> <span class="pre">seconds</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.socket-timeout</span></code></p></td>
<td><p>TCP socket read timeout.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">5</span> <span class="pre">seconds</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.max-connections</span></code></p></td>
<td><p>Maximum number of simultaneous open connections to S3.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">500</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.multipart.min-file-size</span></code></p></td>
<td><p>Minimum file size before multi-part upload to S3 is used.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">16</span> <span class="pre">MB</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3.multipart.min-part-size</span></code></p></td>
<td><p>Minimum multi-part upload part size.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">5</span> <span class="pre">MB</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="s3-data-encryption">
<h3 id="s3-data-encryption">S3 Data Encryption<a class="headerlink" href="#s3-data-encryption" title="Permalink to this headline">#</a></h3>
<p>Presto supports reading and writing encrypted data in S3 using both
server-side encryption with S3 managed keys and client-side encryption using
either the Amazon KMS or a software plugin to manage AES encryption keys.</p>
<p>With <a class="reference external" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html">S3 server-side encryption</a>,
(called <em>SSE-S3</em> in the Amazon documentation) the S3 infrastructure takes care of all encryption and decryption
work (with the exception of SSL to the client, assuming you have <code class="docutils literal notranslate"><span class="pre">hive.s3.ssl.enabled</span></code> set to <code class="docutils literal notranslate"><span class="pre">true</span></code>).
S3 also manages all the encryption keys for you. To enable this, set <code class="docutils literal notranslate"><span class="pre">hive.s3.sse.enabled</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<p>With <a class="reference external" href="http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html">S3 client-side encryption</a>,
S3 stores encrypted data and the encryption keys are managed outside of the S3 infrastructure. Data is encrypted
and decrypted by Presto instead of in the S3 infrastructure. In this case, encryption keys can be managed
either by using the AWS KMS or your own key management system. To use the AWS KMS for key management, set
<code class="docutils literal notranslate"><span class="pre">hive.s3.kms-key-id</span></code> to the UUID of a KMS key. Your AWS credentials or EC2 IAM role will need to be
granted permission to use the given key as well.</p>
<p>To use a custom encryption key management system, set <code class="docutils literal notranslate"><span class="pre">hive.s3.encryption-materials-provider</span></code> to the
fully qualified name of a class which implements the
<a class="reference external" href="http://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/s3/model/EncryptionMaterialsProvider.html">EncryptionMaterialsProvider</a>
interface from the AWS Java SDK. This class will have to be accessible to the Hive Connector through the
classpath and must be able to communicate with your custom key management system. If this class also implements
the <code class="docutils literal notranslate"><span class="pre">org.apache.hadoop.conf.Configurable</span></code> interface from the Hadoop Java API, then the Hadoop configuration
will be passed in after the object instance is created and before it is asked to provision or retrieve any
encryption keys.</p>
</section>
<section id="id1">
<h3 id="id1">S3SelectPushdown<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>S3SelectPushdown enables pushing down projection (SELECT) and predicate (WHERE)
processing to <a class="reference external" href="https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectSELECTContent.html">S3 Select</a>.
With S3SelectPushdown Presto only retrieves the required data from S3 instead of
entire S3 objects reducing both latency and network usage.</p>
<section id="is-s3-select-a-good-fit-for-my-workload">
<h4 id="is-s3-select-a-good-fit-for-my-workload">Is S3 Select a good fit for my workload?<a class="headerlink" href="#is-s3-select-a-good-fit-for-my-workload" title="Permalink to this headline">#</a></h4>
<p>Performance of S3SelectPushdown depends on the amount of data filtered by the
query. Filtering a large number of rows should result in better performance. If
the query doesn’t filter any data then pushdown may not add any additional value
and user will be charged for S3 Select requests. Thus, we recommend that you
benchmark your workloads with and without S3 Select to see if using it may be
suitable for your workload. By default, S3SelectPushdown is disabled and you
should enable it in production after proper benchmarking and cost analysis. For
more information on S3 Select request cost, please see
<a class="reference external" href="https://aws.amazon.com/s3/pricing/">Amazon S3 Cloud Storage Pricing</a>.</p>
<p>Use the following guidelines to determine if S3 Select is a good fit for your
workload:</p>
<ul class="simple">
<li><p>Your query filters out more than half of the original data set.</p></li>
<li><p>Your query filter predicates use columns that have a data type supported by
Presto and S3 Select.
The <code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code>, <code class="docutils literal notranslate"><span class="pre">REAL</span></code>, and <code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code> data types are not supported by S3
Select Pushdown. We recommend using the decimal data type for numerical data.
For more information about supported data types for S3 Select, see the
<a class="reference external" href="https://docs.aws.amazon.com/AmazonS3/latest/dev/s3-glacier-select-sql-reference-data-types.html">Data Types documentation</a>.</p></li>
<li><p>Your network connection between Amazon S3 and the Amazon EMR cluster has good
transfer speed and available bandwidth. Amazon S3 Select does not compress
HTTP responses, so the response size may increase for compressed input files.</p></li>
</ul>
</section>
<section id="considerations-and-limitations">
<h4 id="considerations-and-limitations">Considerations and Limitations<a class="headerlink" href="#considerations-and-limitations" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Only objects stored in CSV format are supported. Objects can be uncompressed
or optionally compressed with gzip or bzip2.</p></li>
<li><p>The “AllowQuotedRecordDelimiters” property is not supported. If this property
is specified, the query fails.</p></li>
<li><p>Amazon S3 server-side encryption with customer-provided encryption keys
(SSE-C) and client-side encryption are not supported.</p></li>
<li><p>S3 Select Pushdown is not a substitute for using columnar or compressed file
formats such as ORC and Parquet.</p></li>
</ul>
</section>
<section id="enabling-s3-select-pushdown">
<h4 id="enabling-s3-select-pushdown">Enabling S3 Select Pushdown<a class="headerlink" href="#enabling-s3-select-pushdown" title="Permalink to this headline">#</a></h4>
<p>You can enable S3 Select Pushdown using the <code class="docutils literal notranslate"><span class="pre">s3_select_pushdown_enabled</span></code>
Hive session property or using the <code class="docutils literal notranslate"><span class="pre">hive.s3select-pushdown.enabled</span></code>
configuration property. The session property will override the config
property, allowing you enable or disable on a per-query basis.</p>
</section>
<section id="understanding-and-tuning-the-maximum-connections">
<h4 id="understanding-and-tuning-the-maximum-connections">Understanding and Tuning the Maximum Connections<a class="headerlink" href="#understanding-and-tuning-the-maximum-connections" title="Permalink to this headline">#</a></h4>
<p>Presto can use its native S3 file system or EMRFS. When using the native FS, the
maximum connections is configured via the <code class="docutils literal notranslate"><span class="pre">hive.s3.max-connections</span></code>
configuration property. When using EMRFS, the maximum connections is configured
via the <code class="docutils literal notranslate"><span class="pre">fs.s3.maxConnections</span></code> Hadoop configuration property.</p>
<p>S3 Select Pushdown bypasses the file systems when accessing Amazon S3 for
predicate operations. In this case, the value of
<code class="docutils literal notranslate"><span class="pre">hive.s3select-pushdown.max-connections</span></code> determines the maximum number of
client connections allowed for those operations from worker nodes.</p>
<p>If your workload experiences the error <em>Timeout waiting for connection from
pool</em>, increase the value of both <code class="docutils literal notranslate"><span class="pre">hive.s3select-pushdown.max-connections</span></code> and
the maximum connections configuration for the file system you are using.</p>
</section>
</section>
</section>
<section id="alluxio-configuration">
<h2 id="alluxio-configuration">Alluxio Configuration<a class="headerlink" href="#alluxio-configuration" title="Permalink to this headline">#</a></h2>
<p>Presto can read and write tables stored in the Alluxio Data Orchestration System
<a class="reference external" href="https://www.alluxio.io/?utm_source=prestodb&amp;utm_medium=prestodocs">Alluxio</a>,
leveraging Alluxio’s distributed block-level read/write caching functionality.
The tables must be created in the Hive metastore with the <code class="docutils literal notranslate"><span class="pre">alluxio://</span></code> location prefix
(see <a class="reference external" href="https://docs.alluxio.io/os/user/2.1/en/compute/Hive.html">Running Apache Hive with Alluxio</a>
for details and examples).
Presto queries will then transparently retrieve and cache files
or objects from a variety of disparate storage systems including HDFS and S3.</p>
<section id="alluxio-client-side-configuration">
<h3 id="alluxio-client-side-configuration">Alluxio Client-Side Configuration<a class="headerlink" href="#alluxio-client-side-configuration" title="Permalink to this headline">#</a></h3>
<p>To configure Alluxio client-side properties on Presto, append the Alluxio
configuration directory (<code class="docutils literal notranslate"><span class="pre">${ALLUXIO_HOME}/conf</span></code>) to the Presto JVM classpath,
so that the Alluxio properties file <code class="docutils literal notranslate"><span class="pre">alluxio-site.properties</span></code> can be loaded as a resource.
Update the Presto <a class="reference internal" href="../installation/deployment.html#presto-jvm-config"><span class="std std-ref">JVM Config</span></a> file <code class="docutils literal notranslate"><span class="pre">etc/jvm.config</span></code> to include the following:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-Xbootclasspath/a:&lt;path-to-alluxio-conf&gt;
</pre></div>
</div>
<p>The advantage of this approach is that all the Alluxio properties are set in
the single <code class="docutils literal notranslate"><span class="pre">alluxio-site.properties</span></code> file. For details, see <a class="reference external" href="https://docs.alluxio.io/os/user/2.1/en/compute/Presto.html#customize-alluxio-user-properties">Customize Alluxio User Properties</a>.</p>
<p>Alternatively, add Alluxio configuration properties to the Hadoop configuration
files (<code class="docutils literal notranslate"><span class="pre">core-site.xml</span></code>, <code class="docutils literal notranslate"><span class="pre">hdfs-site.xml</span></code>) and configure the Hive connector
to use the <a class="reference external" href="#hdfs-configuration">Hadoop configuration files</a> via the
<code class="docutils literal notranslate"><span class="pre">hive.config.resources</span></code> connector property.</p>
</section>
<section id="deploy-alluxio-with-presto">
<h3 id="deploy-alluxio-with-presto">Deploy Alluxio with Presto<a class="headerlink" href="#deploy-alluxio-with-presto" title="Permalink to this headline">#</a></h3>
<p>To achieve the best performance running Presto on Alluxio, it is recommended
to collocate Presto workers with Alluxio workers. This allows reads and writes
to bypass the network. See <a class="reference external" href="https://www.alluxio.io/blog/top-5-performance-tuning-tips-for-running-presto-on-alluxio-1/?utm_source=prestodb&amp;utm_medium=prestodocs">Performance Tuning Tips for Presto with Alluxio</a>
for more details.</p>
</section>
<section id="alluxio-catalog-service">
<h3 id="alluxio-catalog-service">Alluxio Catalog Service<a class="headerlink" href="#alluxio-catalog-service" title="Permalink to this headline">#</a></h3>
<p>An alternative way for Presto to interact with Alluxio is via the
<a class="reference external" href="https://docs.alluxio.io/os/user/stable/en/core-services/Catalog.html?utm_source=prestodb&amp;utm_medium=prestodocs">Alluxio Catalog Service.</a>.
The primary benefits for using the Alluxio Catalog Service are simpler
deployment of Alluxio with Presto, and enabling schema-aware optimizations
such as transparent caching and transformations. Currently, the catalog service
supports read-only workloads.</p>
<p>The Alluxio Catalog Service is a metastore that can cache the information
from different underlying metastores. It currently supports the Hive metastore
as an underlying metastore. In for the Alluxio Catalog to manage the metadata
of other existing metastores, the other metastores must be “attached” to the
Alluxio catalog. To attach an existing Hive metastore to the Alluxio
Catalog, simply use the
<a class="reference external" href="https://docs.alluxio.io/os/user/stable/en/operation/User-CLI.html#attachdb?utm_source=prestodb&amp;utm_medium=prestodocs">Alluxio CLI attachdb command</a>.
The appropriate Hive metastore location and Hive database name need to be
provided.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./bin/alluxio table attachdb hive thrift://HOSTNAME:9083 hive_db_name
</pre></div>
</div>
<p>Once a metastore is attached, the Alluxio Catalog can manage and serve the
information to Presto. To configure the Hive connector for Alluxio
Catalog Service, simply configure the connector to use the Alluxio
metastore type, and provide the location to the Alluxio cluster.
For example, your <code class="docutils literal notranslate"><span class="pre">etc/catalog/catalog_alluxio.properties</span></code> will include
the following (replace the Alluxio address with the appropriate location):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>connector.name=hive-hadoop2
hive.metastore=alluxio
hive.metastore.alluxio.master.address=HOSTNAME:PORT
</pre></div>
</div>
<p>Now, Presto queries can take advantage of the Alluxio Catalog Service, such as
transparent caching and transparent transformations, without any modifications
to existing Hive metastore deployments.</p>
</section>
</section>
<section id="table-statistics">
<h2 id="table-statistics">Table Statistics<a class="headerlink" href="#table-statistics" title="Permalink to this headline">#</a></h2>
<p>The Hive connector automatically collects basic statistics
(<code class="docutils literal notranslate"><span class="pre">numFiles',</span> <span class="pre">``numRows</span></code>, <code class="docutils literal notranslate"><span class="pre">rawDataSize</span></code>, <code class="docutils literal notranslate"><span class="pre">totalSize</span></code>)
on <code class="docutils literal notranslate"><span class="pre">INSERT</span></code> and <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span> <span class="pre">AS</span></code> operations.</p>
<p>The Hive connector can also collect column level statistics:</p>
<table>
<colgroup>
<col style="width: 16%"/>
<col style="width: 84%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Column Type</p></th>
<th class="head"><p>Collectible Statistics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TINYINT</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DECIMAL</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DATE</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code></p></td>
<td><p>number of nulls, number of distinct values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CHAR</span></code></p></td>
<td><p>number of nulls, number of distinct values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARBINARY</span></code></p></td>
<td><p>number of nulls</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p>number of nulls, number of true/false values</p></td>
</tr>
</tbody>
</table>
<p>Automatic column level statistics collection on write is controlled by
the <code class="docutils literal notranslate"><span class="pre">collect-column-statistics-on-write</span></code> catalog session property.</p>
</section>
<section id="collecting-table-and-column-statistics">
<span id="hive-analyze"></span><h2 id="collecting-table-and-column-statistics">Collecting table and column statistics<a class="headerlink" href="#collecting-table-and-column-statistics" title="Permalink to this headline">#</a></h2>
<p>The Hive connector supports collection of table and partition statistics
via the <a class="reference internal" href="../sql/analyze.html"><span class="doc">ANALYZE</span></a> statement. When analyzing a partitioned table,
the partitions to analyze can be specified via the optional <code class="docutils literal notranslate"><span class="pre">partitions</span></code>
property, which is an array containing the values of the partition keys
in the order they are declared in the table schema:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">ANALYZE</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">sales</span><span class="w"> </span><span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="n">partitions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">ARRAY</span><span class="p">[</span><span class="w"></span>
<span class="w">        </span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">'partition1_value1'</span><span class="p">,</span><span class="w"> </span><span class="s1">'partition1_value2'</span><span class="p">],</span><span class="w"></span>
<span class="w">        </span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">'partition2_value1'</span><span class="p">,</span><span class="w"> </span><span class="s1">'partition2_value2'</span><span class="p">]]);</span><span class="w"></span>
</pre></div>
</div>
<p>This query will collect statistics for 2 partitions with keys:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">partition1_value1,</span> <span class="pre">partition1_value2</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">partition2_value1,</span> <span class="pre">partition2_value2</span></code></p></li>
</ul>
</section>
<section id="schema-evolution">
<h2 id="schema-evolution">Schema Evolution<a class="headerlink" href="#schema-evolution" title="Permalink to this headline">#</a></h2>
<p>Hive allows the partitions in a table to have a different schema than the
table. This occurs when the column types of a table are changed after
partitions already exist (that use the original column types). The Hive
connector supports this by allowing the same conversions as Hive:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">varchar</span></code> to and from <code class="docutils literal notranslate"><span class="pre">tinyint</span></code>, <code class="docutils literal notranslate"><span class="pre">smallint</span></code>, <code class="docutils literal notranslate"><span class="pre">integer</span></code> and <code class="docutils literal notranslate"><span class="pre">bigint</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">real</span></code> to <code class="docutils literal notranslate"><span class="pre">double</span></code></p></li>
<li><p>Widening conversions for integers, such as <code class="docutils literal notranslate"><span class="pre">tinyint</span></code> to <code class="docutils literal notranslate"><span class="pre">smallint</span></code></p></li>
</ul>
<p>Any conversion failure will result in null, which is the same behavior
as Hive. For example, converting the string <code class="docutils literal notranslate"><span class="pre">'foo'</span></code> to a number,
or converting the string <code class="docutils literal notranslate"><span class="pre">'1234'</span></code> to a <code class="docutils literal notranslate"><span class="pre">tinyint</span></code> (which has a
maximum value of <code class="docutils literal notranslate"><span class="pre">127</span></code>).</p>
</section>
<section id="avro-schema-evolution">
<h2 id="avro-schema-evolution">Avro Schema Evolution<a class="headerlink" href="#avro-schema-evolution" title="Permalink to this headline">#</a></h2>
<p>Presto supports querying and manipulating Hive tables with Avro storage format which has the schema set
based on an Avro schema file/literal. It is also possible to create tables in Presto which infers the schema
from a valid Avro schema file located locally or remotely in HDFS/Web server.</p>
<p>To specify that Avro schema should be used for interpreting table’s data one must use <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> table property.
The schema can be placed remotely in
HDFS (e.g. <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span> <span class="pre">=</span> <span class="pre">'hdfs://user/avro/schema/avro_data.avsc'</span></code>),
S3 (e.g. <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span> <span class="pre">=</span> <span class="pre">'s3n:///schema_bucket/schema/avro_data.avsc'</span></code>),
a web server (e.g. <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span> <span class="pre">=</span> <span class="pre">'http://example.org/schema/avro_data.avsc'</span></code>)
as well as local file system. This url where the schema is located, must be accessible from the
Hive metastore and Presto coordinator/worker nodes.</p>
<p>The table created in Presto using <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> behaves the same way as a Hive table with <code class="docutils literal notranslate"><span class="pre">avro.schema.url</span></code> or <code class="docutils literal notranslate"><span class="pre">avro.schema.literal</span></code> set.</p>
<p>Example:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">avro</span><span class="p">.</span><span class="n">avro_data</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">   </span><span class="n">id</span><span class="w"> </span><span class="nb">bigint</span><span class="w"></span>
<span class="w"> </span><span class="p">)</span><span class="w"></span>
<span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">   </span><span class="n">format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'AVRO'</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="n">avro_schema_url</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'/usr/local/avro_data.avsc'</span><span class="w"></span>
<span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p>The columns listed in the DDL (<code class="docutils literal notranslate"><span class="pre">id</span></code> in the above example) will be ignored if <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> is specified.
The table schema will match the schema in the Avro schema file. Before any read operation, the Avro schema is
accessed so query result reflects any changes in schema. Thus Presto takes advantage of Avro’s backward compatibility abilities.</p>
<p>If the schema of the table changes in the Avro schema file, the new schema can still be used to read old data.
Newly added/renamed fields <em>must</em> have a default value in the Avro schema file.</p>
<p>The schema evolution behavior is as follows:</p>
<ul class="simple">
<li><p>Column added in new schema:
Data created with an older schema will produce a <em>default</em> value when table is using the new schema.</p></li>
<li><p>Column removed in new schema:
Data created with an older schema will no longer output the data from the column that was removed.</p></li>
<li><p>Column is renamed in the new schema:
This is equivalent to removing the column and adding a new one, and data created with an older schema
will produce a <em>default</em> value when table is using the new schema.</p></li>
<li><p>Changing type of column in the new schema:
If the type coercion is supported by Avro or the Hive connector, then the conversion happens.
An error is thrown for incompatible types.</p></li>
</ul>
<section id="limitations">
<h3 id="limitations">Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">#</a></h3>
<p>The following operations are not supported when <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> is set:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span> <span class="pre">AS</span></code> is not supported.</p></li>
<li><p>Using partitioning(<code class="docutils literal notranslate"><span class="pre">partitioned_by</span></code>) or bucketing(<code class="docutils literal notranslate"><span class="pre">bucketed_by</span></code>) columns are not supported in <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ALTER</span> <span class="pre">TABLE</span></code> commands modifying columns are not supported.</p></li>
</ul>
</section>
</section>
<section id="procedures">
<h2 id="procedures">Procedures<a class="headerlink" href="#procedures" title="Permalink to this headline">#</a></h2>
<p>Use the <a class="reference internal" href="../sql/call.html"><span class="doc">CALL</span></a> statement to perform data manipulation or
administrative tasks. Procedures must include a qualified catalog name, if your
Hive catalog is called <code class="docutils literal notranslate"><span class="pre">web</span></code>:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CALL</span><span class="w"> </span><span class="n">web</span><span class="p">.</span><span class="k">system</span><span class="p">.</span><span class="n">example_procedure</span><span class="p">()</span><span class="w"></span>
</pre></div>
</div>
<p>The following procedures are available:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">system.create_empty_partition(schema_name,</span> <span class="pre">table_name,</span> <span class="pre">partition_columns,</span> <span class="pre">partition_values)</span></code></p>
<blockquote>
<div><p>Create an empty partition in the specified table.</p>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">system.sync_partition_metadata(schema_name,</span> <span class="pre">table_name,</span> <span class="pre">mode,</span> <span class="pre">case_sensitive)</span></code></p>
<blockquote>
<div><p>Check and update partitions list in metastore. There are three modes available:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ADD</span></code> : add any partitions that exist on the file system but not in the metastore.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DROP</span></code>: drop any partitions that exist in the metastore but not on the file system.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FULL</span></code>: perform both <code class="docutils literal notranslate"><span class="pre">ADD</span></code> and <code class="docutils literal notranslate"><span class="pre">DROP</span></code>.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">case_sensitive</span></code> argument is optional. The default value is <code class="docutils literal notranslate"><span class="pre">true</span></code> for compatibility
with Hive’s <code class="docutils literal notranslate"><span class="pre">MSCK</span> <span class="pre">REPAIR</span> <span class="pre">TABLE</span></code> behavior, which expects the partition column names in
file system paths to use lowercase (e.g. <code class="docutils literal notranslate"><span class="pre">col_x=SomeValue</span></code>). Partitions on the file system
not conforming to this convention are ignored, unless the argument is set to <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</div></blockquote>
</li>
</ul>
</section>
<section id="extra-hidden-columns">
<h2 id="extra-hidden-columns">Extra Hidden Columns<a class="headerlink" href="#extra-hidden-columns" title="Permalink to this headline">#</a></h2>
<p>The Hive connector exposes extra hidden metadata columns in Hive tables. You can query these
columns as a part of SQL query like any other columns of the table.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">$path</span></code> : Filepath for the given row data</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$file_size</span></code> : Filesize for the given row</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$file_modified_time</span></code> : Last file modified time for the given row</p></li>
</ul>
</section>
<section id="examples">
<h2 id="examples">Examples<a class="headerlink" href="#examples" title="Permalink to this headline">#</a></h2>
<p>The Hive connector supports querying and manipulating Hive tables and schemas
(databases). While some uncommon operations will need to be performed using
Hive directly, most operations can be performed using Presto.</p>
<p>Create a new Hive schema named <code class="docutils literal notranslate"><span class="pre">web</span></code> that will store tables in an
S3 bucket named <code class="docutils literal notranslate"><span class="pre">my-bucket</span></code>:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="w"></span>
<span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="k">location</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'s3://my-bucket/'</span><span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p>Create a new Hive table named <code class="docutils literal notranslate"><span class="pre">page_views</span></code> in the <code class="docutils literal notranslate"><span class="pre">web</span></code> schema
that is stored using the ORC file format, partitioned by date and
country, and bucketed by user into <code class="docutils literal notranslate"><span class="pre">50</span></code> buckets (note that Hive
requires the partition columns to be the last columns in the table):</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_views</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">  </span><span class="n">view_time</span><span class="w"> </span><span class="k">timestamp</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">user_id</span><span class="w"> </span><span class="nb">bigint</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">page_url</span><span class="w"> </span><span class="nb">varchar</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">ds</span><span class="w"> </span><span class="nb">date</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">country</span><span class="w"> </span><span class="nb">varchar</span><span class="w"></span>
<span class="p">)</span><span class="w"></span>
<span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">  </span><span class="n">format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'ORC'</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">partitioned_by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">'ds'</span><span class="p">,</span><span class="w"> </span><span class="s1">'country'</span><span class="p">],</span><span class="w"></span>
<span class="w">  </span><span class="n">bucketed_by</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">'user_id'</span><span class="p">],</span><span class="w"></span>
<span class="w">  </span><span class="n">bucket_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">50</span><span class="w"></span>
<span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p>Drop a partition from the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">DELETE</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_views</span><span class="w"></span>
<span class="k">WHERE</span><span class="w"> </span><span class="n">ds</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">DATE</span><span class="w"> </span><span class="s1">'2016-08-09'</span><span class="w"></span>
<span class="w">  </span><span class="k">AND</span><span class="w"> </span><span class="n">country</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'US'</span><span class="w"></span>
</pre></div>
</div>
<p>Add an empty partition to the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CALL</span><span class="w"> </span><span class="k">system</span><span class="p">.</span><span class="n">create_empty_partition</span><span class="p">(</span><span class="w"></span>
<span class="w">    </span><span class="k">schema_name</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s1">'web'</span><span class="p">,</span><span class="w"></span>
<span class="w">    </span><span class="k">table_name</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s1">'page_views'</span><span class="p">,</span><span class="w"></span>
<span class="w">    </span><span class="n">partition_columns</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">'ds'</span><span class="p">,</span><span class="w"> </span><span class="s1">'country'</span><span class="p">],</span><span class="w"></span>
<span class="w">    </span><span class="n">partition_values</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">'2016-08-09'</span><span class="p">,</span><span class="w"> </span><span class="s1">'US'</span><span class="p">]);</span><span class="w"></span>
</pre></div>
</div>
<p>Query the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_views</span><span class="w"></span>
</pre></div>
</div>
<p>List the partitions of the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="ss">"page_views$partitions"</span><span class="w"></span>
</pre></div>
</div>
<p>Create an external Hive table named <code class="docutils literal notranslate"><span class="pre">request_logs</span></code> that points at
existing data in S3:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">request_logs</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">  </span><span class="n">request_time</span><span class="w"> </span><span class="k">timestamp</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">url</span><span class="w"> </span><span class="nb">varchar</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">ip</span><span class="w"> </span><span class="nb">varchar</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">user_agent</span><span class="w"> </span><span class="nb">varchar</span><span class="w"></span>
<span class="p">)</span><span class="w"></span>
<span class="k">WITH</span><span class="w"> </span><span class="p">(</span><span class="w"></span>
<span class="w">  </span><span class="n">format</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'TEXTFILE'</span><span class="p">,</span><span class="w"></span>
<span class="w">  </span><span class="n">external_location</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'s3://my-bucket/data/logs/'</span><span class="w"></span>
<span class="p">)</span><span class="w"></span>
</pre></div>
</div>
<p>Drop the external table <code class="docutils literal notranslate"><span class="pre">request_logs</span></code>. This only drops the metadata
for the table. The referenced data directory is not deleted:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">DROP</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">request_logs</span><span class="w"></span>
</pre></div>
</div>
<p>Drop a schema:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">DROP</span><span class="w"> </span><span class="k">SCHEMA</span><span class="w"> </span><span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="w"></span>
</pre></div>
</div>
</section>
<section id="hive-connector-limitations">
<h2 id="hive-connector-limitations">Hive Connector Limitations<a class="headerlink" href="#hive-connector-limitations" title="Permalink to this headline">#</a></h2>
<p><a class="reference internal" href="../sql/delete.html"><span class="doc">DELETE</span></a> is only supported if the <code class="docutils literal notranslate"><span class="pre">WHERE</span></code> clause matches entire partitions.</p>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="elasticsearch.html" title="Elasticsearch Connector"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> Previous </span> Elasticsearch Connector </span>
              </div>
            </a>
          
          
            <a href="hive-security.html" title="Hive Security Configuration"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> Next </span> Hive Security Configuration </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
          <div class="md-footer-copyright__highlight">
              &#169; Copyright The Presto Foundation. All rights reserved. Presto is a registered trademark of LF Projects, LLC.
              
          </div>
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
  </body>
</html>