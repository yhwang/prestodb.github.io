<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://prestodb.io/blog</id>
    <title> Blog</title>
    <updated>2021-11-22T06:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://prestodb.io/blog"/>
    <subtitle>The best place to stay up-to-date with the latest  news and events.</subtitle>
    <logo>https://prestodb.io/img/presto.png</logo>
    <entry>
        <title type="html"><![CDATA[Common Sub-Expression optimization]]></title>
        <id>https://prestodb.io/blog/2021/11/22/common-sub-expression-optimization.html</id>
        <link href="https://prestodb.io/blog/2021/11/22/common-sub-expression-optimization.html"/>
        <updated>2021-11-22T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<h2><a class="anchor" aria-hidden="true" id="the-problem"></a><a href="#the-problem" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The problem</h2>
<p>One common pattern we see in some analytical workloads is the repeated use of the same, often times expensive expression. Look at the following query plan for example:</p>
<p><img src="/img/blog/2021-11-19-common-sub-expression-optimization/query-plan.png" alt="Query Plan"></p>
<p>The expression <code>JSON_PARSE(features)</code> is used 6 times, and casted to different <code>ROW</code> structures for further processing. Traditionally, Presto would just execute the expression 6 times, in 6 separate projections. Since Presto would generate efficient bytecode for each projection, this would not be a problem as long as the expression itself is not expensive. For example, executing <code>x+y</code> 6 times in a cache efficient way would not necessarily incur a big performance overhead. However, running expensive string manipulations like <code>JSON_PARSE</code> or <code>REGEX</code> operations multiple times could quickly add up.</p>
]]></summary>
        <author>
            <name>Rongrong Zhong</name>
            <uri>https://www.linkedin.com/in/rongrong-zhong-31aa8a8/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Scaling with Presto on Spark]]></title>
        <id>https://prestodb.io/blog/2021/10/26/Scaling-with-Presto-on-Spark.html</id>
        <link href="https://prestodb.io/blog/2021/10/26/Scaling-with-Presto-on-Spark.html"/>
        <updated>2021-10-26T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>Co-authors</strong><br>
<a href="https://www.linkedin.com/in/shradha-ambekar-a0504714">Shradha Ambekar</a>, Staff Software Engineer at <a href="https://www.intuit.com/">Intuit</a><br>
<a href="https://www.linkedin.com/in/ariel-weisberg-a5b6899">Ariel Weisberg</a>, Software Engineer at <a href="https://www.facebook.com/">Facebook</a></p>
<h2><a class="anchor" aria-hidden="true" id="overview"></a><a href="#overview" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p>Presto was originally designed to run interactive queries against data warehouses, but now it has evolved into a unified SQL engine on top of open data lake analytics for both interactive and batch workloads. Popular workloads on data lakes include:</p>
<h3><a class="anchor" aria-hidden="true" id="1-reporting-and-dashboarding"></a><a href="#1-reporting-and-dashboarding" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1. Reporting and dashboarding</h3>
<p>This includes serving custom reporting for both internal and external developers for business insights and also many organizations using Presto for interactive A/B testing analytics. A defining characteristic of this use case is a requirement for low latency. It requires tens to hundreds of milliseconds at very high QPS, and not surprisingly this use case is almost exclusively using Presto and that's what Presto is designed for.</p>
<h3><a class="anchor" aria-hidden="true" id="2-data-science-with-sql-notebooks"></a><a href="#2-data-science-with-sql-notebooks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2. Data science with SQL notebooks</h3>
<p>This use case is one of ad hoc analysis and typically needs moderate latency ranging from seconds to minutes. These are the queries of data scientist, and business analysts who want to perform compact ad hoc analysis to understand product usage, for example, user trends and how to improve the product. The QPS is relatively lower because users have to manually initiate these queries.</p>
<h3><a class="anchor" aria-hidden="true" id="3-batch-processing-for-large-data-pipelines"></a><a href="#3-batch-processing-for-large-data-pipelines" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3. Batch processing for large data pipelines</h3>
<p>These are scheduled jobs that are running every day, hour, or whenever the data is ready. They often contain queries over very large volumes of data and the latency can be up to tens of hours and processing can range from CPU days to years and terabytes to petabytes of data.</p>
<p>Presto works exceptionally effectively for ad-hoc or interactive queries today, and even some batch queries, with the constraint that the entire query must fit in memory and run quickly enough that fault tolerance is not required. Most ETL batch workloads that don’t fit in this box are running on “very big data” compute engines like Apache Spark. Having multiple compute engines with different SQL dialects and APIs makes managing and scaling these workloads complicated for data platform teams. Hence, Facebook decided to simplify and build Presto on Spark as the path to further scale Presto. Before we get into Presto on Spark, let me explain a bit more about the architecture of each of these two popular engines.</p>
]]></summary>
        <author>
            <name>Rohan Pednekar</name>
            <uri>https://www.linkedin.com/in/pednero</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Native Parquet Writer for Presto]]></title>
        <id>https://prestodb.io/blog/2021/06/29/native-parquet-writer-for-presto.html</id>
        <link href="https://prestodb.io/blog/2021/06/29/native-parquet-writer-for-presto.html"/>
        <updated>2021-06-29T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>Pinterest:</strong> Lu Niu</p>
<p><strong>Twitter:</strong> Zhenxiao Luo</p>
<h2><a class="anchor" aria-hidden="true" id="overview"></a><a href="#overview" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p>With the wide deployment of Presto in a growing number of companies, Presto is used not only for queries, but also for data ingestion and ETL jobs. There is a need to improve Presto’s file writer performance, especially for popular columnar file formats, e.g. Parquet, and ORC. In this article, we introduce the brand new native Parquet writer for Presto, which writes directly from Presto's columnar data structure to Parquet's columnar values, with up to 6X throughput improvement and less CPU and memory overhead.</p>
]]></summary>
        <author>
            <name>Lu Niu</name>
            <uri>https://www.linkedin.com/in/luniu/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Presto Foundation and PrestoDB: Our Commitment to the Presto Open Source Community]]></title>
        <id>https://prestodb.io/blog/2021/06/14/Commitment-to-Presto-Open-Source-Community.html</id>
        <link href="https://prestodb.io/blog/2021/06/14/Commitment-to-Presto-Open-Source-Community.html"/>
        <updated>2021-06-14T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>Authors</strong></p>
<ul>
<li>Girish Baliga, Chair, Presto Foundation, Presto Foundation Member: <a href="https://www.uber.com/">Uber</a></li>
<li>Tim Meehan, Chair, Presto Foundation, Technical Steering Committee, Presto Foundation Member: <a href="https://www.facebook.com/">Facebook</a></li>
<li>Dipti Borkar, Chair, Presto Foundation, Outreach, Presto Foundation Member: <a href="https://ahana.io/">Ahana</a></li>
<li>Amit Chopra, Board member, Presto Foundation Member: <a href="https://www.facebook.com/">Facebook</a></li>
<li>Zhenxiao Luo , Board member, Presto Foundation Member: <a href="https://twitter.com/">Twitter</a></li>
<li>Arijit Bandyopadhyay, Board member, Presto Foundation Member: <a href="https://intel.com/">Intel</a></li>
<li>Steven Mih, Board member, Presto Foundation Member: <a href="https://ahana.io/">Ahana</a></li>
<li>Bin Fan, Outreach team member, Presto Foundation Member: <a href="https://www.alluxio.io/">Alluxio</a></li>
</ul>
<p>We recently wrapped up an amazing PrestoCon Day attended by over 600 people from across the globe. The technical discussions and the panel was a clear indication of the growing community. We showcased a number of features contributed by various companies that continue to advance the mission of Presto open source, reiterating our commitment to grow the Presto community and support the continued improvement of the core technology.</p>
]]></summary>
        <author>
            <name>Girish Baliga, Tim Meehan, Dipti Borkar, Amit Chopra, Zhenxiao Luo, Arijit Bandyopadhyay, Steven Mih, Bin Fan</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[RaptorX: Building a 10X Faster Presto]]></title>
        <id>https://prestodb.io/blog/2021/02/04/raptorx.html</id>
        <link href="https://prestodb.io/blog/2021/02/04/raptorx.html"/>
        <updated>2021-02-04T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<div style="text-align: justify">
<p><strong>Facebook:</strong> Abhinav Sharma, Amit Dutta, Baldeep Hira, Biswapesh Chattopadhyay, James Sun, Jialiang Tan, Ke Wang, Lin Liu, Naveen Cherukuri, Nikhil Collooru, Peter Na, Prashant Nema, Rohit Jain, Saksham Sachdev, Sergey Pershin, Shixuan Fan, Varun Gajjala</p>
<p><strong>Alluxio:</strong> Bin Fan, Calvin Jia, Haoyuan Li</p>
<p><strong>Twitter:</strong> Zhenxiao Luo</p>
<p><strong>Pinterest:</strong> Lu Niu</p>
<p><em>RaptorX is an internal project name aiming to boost query latency significantly beyond what vanilla Presto is capable of. This blog post introduces the hierarchical cache work, which is the key building block for RaptorX. With the support of the cache, we are able to boost query performance by 10X. This new architecture can beat performance oriented connectors like Raptor with the added benefit of continuing to work with disaggregated storage.</em></p>
]]></summary>
        <author>
            <name>James Sun</name>
            <uri>https://www.linkedin.com/in/yutiansun/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[2020 Recap - A Year with Presto]]></title>
        <id>https://prestodb.io/blog/2021/01/12/2020-recap-year-with-presto.html</id>
        <link href="https://prestodb.io/blog/2021/01/12/2020-recap-year-with-presto.html"/>
        <updated>2021-01-12T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Tl;dr: 2020 was a huge year for the Presto community. We held our first major conference, PrestoCon, the biggest Presto event ever. We had a massive expansion of our meetup groups with more than 20 sessions held throughout the year, and significant innovations were contributed to Presto!</p>
<p>This year has certainly been unique, to say the least. As chairperson of the Presto Foundation Outreach Committee, the term “outreach” took on a whole new meaning this year. But through the challenges of 2020, we adopted new ways to connect. We continued to build and engage with the Presto community in a new “virtual” way, and I couldn’t be more proud of all we’ve accomplished as a community in 2020.</p>
<p>So what did the Presto Foundation do in 2020?</p>
]]></summary>
        <author>
            <name>Dipti Borkar</name>
            <uri>https://www.linkedin.com/in/diptiborkar/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Using OptimizedTypedSet to Improve Map and Array Functions]]></title>
        <id>https://prestodb.io/blog/2020/12/04/typedset.html</id>
        <link href="https://prestodb.io/blog/2020/12/04/typedset.html"/>
        <updated>2020-12-04T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Function evaluation is a big part of projection CPU cost. Recently we optimized a set of functions that use <code>TypedSet</code>, e.g.  <code>map_concat</code>, <code>array_union</code>, <code>array_intersect</code>, and <code>array_except</code>. By introducing a new <code>OptimizedTypeSet</code>, the above functions saw improvements in several dimensions:</p>
<ul>
<li>Up to 80% reduction in wall time and CPU time in JMH benchmarks</li>
<li>Reserved memory reduced by 5%</li>
<li>Allocation rate reduced by 80%</li>
</ul>
<p>Furthermore, OptimizedTypeSet resolves the long standing issue of throwing <code>EXCEEDED_FUNCTION_MEMORY_LIMIT</code> for large incoming blocks: &quot;The input to function_name is too large. More than 4MB of memory is needed to hold the intermediate hash set.”</p>
<p>The <code>OptimizedTypeSet</code> and improvements to the above mentioned functions are merged to master, and will be available from Presto 0.244.</p>
]]></summary>
        <author>
            <name>Ying Su</name>
            <uri>https://www.linkedin.com/in/ying-su-b00b81107/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PrestoCon and Growing Industry Consortium - Intel and Upsolver Join Presto Foundation]]></title>
        <id>https://prestodb.io/blog/2020/11/20/prestocon-and-foundation-update.html</id>
        <link href="https://prestodb.io/blog/2020/11/20/prestocon-and-foundation-update.html"/>
        <updated>2020-11-20T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Presto Foundation joined the Linux Foundation over a year ago, and has been focused on growing the <a href="http://prestodb.io">Presto open source project</a> and community. We encourage industry involvement with an <a href="https://github.com/prestodb/foundation#presto-foundation-related-documents">open charter</a>, <a href="https://github.com/prestodb/foundation/blob/master/PRINCIPLES.md#presto-foundation-principles">clear guiding principles</a>, and <a href="https://github.com/prestodb/foundation/blob/master/GOALS.md#presto-foundation-pf-strategic-goals">community-oriented goals</a>. We recently hosted <a href="https://prestodb.io/prestocon.html">PrestoCon 2020</a>, our first annual community conference, which was widely attended and well represented by Presto community members. We also warmly welcome Intel and Upsolver who recently joined the Presto Foundation.</p>
]]></summary>
        <author>
            <name>Girish Baliga</name>
            <uri>https://github.com/gbbaliga</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Presto Enables Internal Log Data Analysis at Drift]]></title>
        <id>https://prestodb.io/blog/2020/10/29/presto-at-drift.html</id>
        <link href="https://prestodb.io/blog/2020/10/29/presto-at-drift.html"/>
        <updated>2020-10-29T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>I’m a Senior Software Engineer in the data group at Drift, a conversational marketing platform that is used for qualifying leads faster, automatically booking meetings and connecting customers to the right business solutions more efficiently. I’ve used Presto quite a bit throughout my career, and I want to first give readers a quick overview of how Presto has enabled my team at Drift to quickly and cost-effectively analyze distributed logs at scale. Then I will share how we used and benefited from Presto at Vistaprint, where I worked previously.</p>
]]></summary>
        <author>
            <name>Arun Venkateswaran</name>
            <uri>https://github.com/venkaa6</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Even Faster Unnest]]></title>
        <id>https://prestodb.io/blog/2020/08/20/unnest.html</id>
        <link href="https://prestodb.io/blog/2020/08/20/unnest.html"/>
        <updated>2020-08-20T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Ying Su, Masha Basmanova, Orri Erling</p>
<p>Unnest is a common operation in Facebook’s daily Presto workload. It converts an <code>ARRAY</code>, <code>MAP</code>, or <code>ROW</code> into a flat relation. Its original implementation used deep copy all the time and was very inefficient. In <a href="https://prestosql.io/blog/2019/08/23/unnest-operator-performance-enhancements.html">Unnest Operator Performance Enhancement with Dictionary Blocks</a>, the author improved the Unnest operator by up to 10x in CPU and elapsed times by using <code>DictionaryBlock</code> when possible. We went one step further and improved it for another 5-10x.</p>
]]></summary>
        <author>
            <name>Ying Su</name>
            <uri>https://www.linkedin.com/in/ying-su-b00b81107/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Getting Started with PrestoDB and Aria Scan Optimizations]]></title>
        <id>https://prestodb.io/blog/2020/08/14/getting-started-and-aria.html</id>
        <link href="https://prestodb.io/blog/2020/08/14/getting-started-and-aria.html"/>
        <updated>2020-08-14T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>This article was originally published by Adam on June 15th, 2020 over at his blog at <a href="https://datacatessen.com/blog/prestodb-aria/">datacatessen.com</a>.</p>
<hr>
<p><a href="https://prestodb.io">PrestoDB</a> recently released a set of experimental features under their Aria project in order to increase table scan performance of data stored in ORC files via the Hive Connector.  In this post, we'll check out these new features at a very basic level using a test environment of PrestoDB on Docker.  To find out more about the Aria features, you can check out the <a href="https://engineering.fb.com/data-infrastructure/aria-presto/">Facebook Engineering</a> blog post which was published June 2019.</p>
]]></summary>
        <author>
            <name>Adam Shook</name>
            <uri>https://www.linkedin.com/in/adamjshook</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Building a high-performance platform on AWS to support real-time gaming services using Presto and Alluxio]]></title>
        <id>https://prestodb.io/blog/2020/08/06/presto-in-ea.html</id>
        <link href="https://prestodb.io/blog/2020/08/06/presto-in-ea.html"/>
        <updated>2020-08-06T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>Authors:</strong> Teng Wang, Du Li, Yu Jin and Sundeep Narravula</p>
<p>Electronic Arts (EA) is a leading company in the gaming industry, providing dozens of games to serve billions of users worldwide each year.
Making near real-time decisions for EA’s online services is critical for our business.
This blog describes a data platform on AWS based on Presto and Alluxio to support online services with instantaneous response within the gaming industry.</p>
]]></summary>
        <author>
            <name>Teng Wang</name>
            <uri>https://www.linkedin.com/in/teng-wang-9b8732194/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[PrestoDB and Apache Hudi]]></title>
        <id>https://prestodb.io/blog/2020/08/04/prestodb-and-hudi.html</id>
        <link href="https://prestodb.io/blog/2020/08/04/prestodb-and-hudi.html"/>
        <updated>2020-08-04T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>Co-author:</strong> <a href="https://www.linkedin.com/in/brandon-scheller-a00851ab">Brandon Scheller</a></p>
<p><a href="https://hudi.apache.org">Apache Hudi</a> is a fast growing data lake storage system that helps organizations build and manage petabyte-scale data lakes. Hudi brings stream style processing to batch-like big data by introducing primitives such as upserts, deletes and incremental queries. These features help surface faster, fresher data on a unified serving layer. Hudi tables can be stored on the Hadoop Distributed File System (HDFS) or cloud stores and integrates well with popular query engines such as <a href="https://prestodb.io">Presto</a>, <a href="https://hive.apache.org">Apache Hive</a>, <a href="https://spark.apache.org">Apache Spark</a> and <a href="https://impala.apache.org">Apache Impala</a>. Given Hudi pioneered a new model that moved beyond just writing files to a more managed storage layer that interops with all major query engines, there were interesting learnings on how integration points evolved.</p>
<p>In this blog we are going to discuss how the Presto-Hudi integration has evolved over time and also discuss upcoming file listing and query planning improvements to Presto-Hudi queries.</p>
]]></summary>
        <author>
            <name>Bhavani Sudha Saktheeswaran</name>
            <uri>https://www.linkedin.com/in/bhasudha</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Running Presto in a Hybrid Cloud Architecture]]></title>
        <id>https://prestodb.io/blog/2020/07/17/alluxio-hybrid-cloud.html</id>
        <link href="https://prestodb.io/blog/2020/07/17/alluxio-hybrid-cloud.html"/>
        <updated>2020-07-17T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Migrating SQL workloads from a fully on-premise environment to cloud infrastructure has numerous benefits, including alleviating resource contention and reducing costs by paying for computation resources on an on-demand basis. In the case of Presto running on data stored in HDFS, the separation of compute in the cloud and storage on-premises is apparent since Presto’s architecture enables the storage and compute components to operate independently. The critical issue in this hybrid environment of Presto in the cloud retrieving HDFS data from an on-premise environment is the network latency between the two clusters.</p>
<p>This crucial bottleneck severely limits performance of any workload since a significant portion of its time is spent transferring the requested data between networks that could be residing in geographically disparate locations. As a result, most companies copy their data into a cloud environment and maintain that duplicate data, also known as Lift and Shift. Companies with compliance and data sovereignty requirements may even prevent organizations from copying data into the cloud. This approach is not scalable and requires introducing a lot of manual effort to achieve reasonable results. This article introduces <a href="https://www.alluxio.io/">Alluxio</a> to serve as a <a href="https://www.alluxio.io/data-orchestration/">data orchestration</a> layer to help serve data to Presto efficiently, as opposed to either directly querying the distant HDFS cluster or manually providing a localized copy of the data to Presto in a cloud cluster.</p>
]]></summary>
        <author>
            <name>Adit Madan</name>
            <uri>https://www.linkedin.com/in/aditm/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Data Lake Analytics: Alibaba's Federated Cloud Strategy]]></title>
        <id>https://prestodb.io/blog/2020/06/30/data-lake-analytics-blog.html</id>
        <link href="https://prestodb.io/blog/2020/06/30/data-lake-analytics-blog.html"/>
        <updated>2020-06-30T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Presto is known to be a high-performance, distributed SQL query engine for Big Data. It offers large-scale data analytics with multiple connectors for accessing various data sources. This capability enables the Presto users to further extend some features to build a large-scale data federation service on cloud. <br>
<br>
Alibaba Data Lake Analytics embraces Presto’s federated query engine capability and has accumulated a number of successful business use cases that signify the power of Presto's analytics capability.
<br><br></p>
]]></summary>
        <author>
            <name>George Wang</name>
            <uri>https://www.linkedin.com/in/george-wang-9a5a46190/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving Presto Latencies with Alluxio Data Caching]]></title>
        <id>https://prestodb.io/blog/2020/06/16/alluxio-datacaching.html</id>
        <link href="https://prestodb.io/blog/2020/06/16/alluxio-datacaching.html"/>
        <updated>2020-06-16T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>Facebook:</strong> Rohit Jain, James Sun, Ke Wang, Shixuan Fan, Biswapesh Chattopadhyay, Baldeep Hira</p>
<p><strong>Alluxio:</strong> Bin Fan, Calvin Jia, Haoyuan Li</p>
<p>The Facebook Presto team has been collaborating with <a href="https://www.alluxio.io/">Alluxio</a> on an open source data caching solution for Presto.
This is required for multiple Facebook use-cases to improve query latency for queries that scan data from remote sources such as HDFS.
We have observed significant improvements in query latencies and IO scans in our experiments.
<br><br></p>
]]></summary>
        <author>
            <name>Rohit Jain</name>
            <uri>https://www.linkedin.com/in/jain-rohit/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spatial Joins 1: Local Spatial Joins]]></title>
        <id>https://prestodb.io/blog/2020/05/07/local-spatial-joins.html</id>
        <link href="https://prestodb.io/blog/2020/05/07/local-spatial-joins.html"/>
        <updated>2020-05-07T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>A common type of spatial query involves relating one table of geometric
objects (e.g., a table <code>population_centers</code> with columns
<code>population, latitude, longitude</code>) with another such table (e.g., a table
<code>counties</code> with columns <code>county_name, boundary_wkt</code>), such as calculating
for each county the population sum of all population centers contained
within it. These kinds of calculations are called <em>spatial joins</em>. While
doing it for a single row each from <code>population_centers</code> and <code>counties</code> is
manageable, doing it efficiently for two large tables is challenging. In this
post, we'll talk about the machinery that Presto has built to make these
queries blazingly fast.</p>
]]></summary>
        <author>
            <name>James Gill</name>
            <uri>https://www.linkedin.com/in/jagill/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Engineering SQL Support on Apache Pinot at Uber]]></title>
        <id>https://prestodb.io/blog/2020/03/18/uber-pinot.html</id>
        <link href="https://prestodb.io/blog/2020/03/18/uber-pinot.html"/>
        <updated>2020-03-18T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>The article,  <a href="https://eng.uber.com/engineering-sql-support-on-apache-pinot/">Engineering SQL Support on Apache Pinot at Uber</a>, was originally published by Uber on the Uber Engineering Blog on January 15, 2020. Check out <a href="https://eng.uber.com/">eng.uber.com</a> for more articles about Uber's engineering work and follow Uber Engineering at <a href="https://twitter.com/UberEng">@UberEng</a> and Uber Open Source at <a href="https://twitter.com/UberOpenSource">@UberOpenSouce</a> on Twitter for updates from our teams.</p>
<p><img src="/img/blog/2020-03-18-uber-pinot/shiny-thing.png" alt=""></p>
<p>Uber leverages real-time analytics on aggregate data to improve the user experience across our products, from <a href="https://eng.uber.com/uber-eats-risk-team/">fighting fraudulent behavior</a> on Uber Eats to <a href="https://eng.uber.com/forecasting-introduction/">forecasting demand</a> on our platform.</p>
<p>As Uber’s operations became more complex and we offered additional features and services through our platform, we needed a way to generate more timely analytics on our aggregated marketplace data to better understand how our products were being used. Specifically, we needed our Big Data stack to support cross-table queries as well as nested queries, both requirements that would enable us to write more flexible ad hoc queries to keep up with the growth of our business.</p>
<p>To resolve these issues, we built a solution that linked <a href="http://prestodb.github.io/">Presto</a>, a query engine that supports full ANSI SQL, and <a href="https://pinot.apache.org/">Pinot</a>, a real-time OLAP (online analytical processing) datastore. This married solution allows users to write ad-hoc SQL queries, empowering teams to unlock significant analysis capabilities.</p>
<p>By engineering full SQL support on Apache Pinot, users of our Big Data stack can now write complex SQL queries as well as join different tables in Pinot with those in other datastores at Uber. This new solution enables operations teams with basic SQL knowledge to build dashboards for quick analysis and reporting on aggregated data without having to spend extra time working with engineers on data modelling or building data pipelines, leading to efficiency gains and resource savings across the company.</p>
]]></summary>
        <author>
            <name>Haibo Wang</name>
            <uri>https://www.linkedin.com/in/haibowangcmu/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Querying Nested Data with Lambda Functions]]></title>
        <id>https://prestodb.io/blog/2020/03/02/presto-lambda.html</id>
        <link href="https://prestodb.io/blog/2020/03/02/presto-lambda.html"/>
        <updated>2020-03-02T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Denormalized data with nested values (e.g. array/map) have become omnipresent in this Big Data era, as a lot of data naturally conforms to a nested representation [1, 2]. As a result it is important to provide an efficient and convenient way to query nested data. SQL traditionally does not include support for this.</p>
<p>The pioneering work of Dremel proposed an extension to SQL based on recursive relational algebra to allow querying nested records [1], and is now available in BigQuery and the SQL:2016 standard. The following example shows how to transform array elements with this (adapted from <a href="https://cloud.google.com/bigquery/docs/reference/standard-sql/arrays#creating-arrays-from-subqueries">BigQuery Docs</a>):</p>
<pre><code class="hljs css language-sql"><span class="hljs-keyword">SELECT</span> elements,
    <span class="hljs-built_in">ARRAY</span>(<span class="hljs-keyword">SELECT</span> v * <span class="hljs-number">2</span>
          <span class="hljs-keyword">FROM</span> <span class="hljs-keyword">UNNEST</span>(elements) <span class="hljs-keyword">AS</span> v) <span class="hljs-keyword">AS</span> multiplied_elements
<span class="hljs-keyword">FROM</span> (
    <span class="hljs-keyword">VALUES</span>
        (<span class="hljs-built_in">ARRAY</span>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]),
        (<span class="hljs-built_in">ARRAY</span>[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>]),
        (<span class="hljs-built_in">ARRAY</span>[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>, <span class="hljs-number">64</span>])
) <span class="hljs-keyword">AS</span> t(elements)

    elements    | multiplied_elements
<span class="hljs-comment">----------------+---------------------</span>
 [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]         | [<span class="hljs-number">2</span>, <span class="hljs-number">4</span>]
 [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>]      | [<span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">18</span>]
 [<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>, <span class="hljs-number">64</span>] | [<span class="hljs-number">2</span>, <span class="hljs-number">8</span>, <span class="hljs-number">32</span>, <span class="hljs-number">128</span>]
(<span class="hljs-number">3</span> <span class="hljs-keyword">rows</span>)
</code></pre>
<p>While nested relational algebra provides an elegant and unified approach to query nested data, we found it could be challenging for users to track the “unnest stack” in mind when writing the query. In our experience, users are more comfortable to apply a given function (e.g lambda) to each element in the collection. This motivates us to introduce lambda expressions into Presto to help query nested data, as illustrated below:</p>
<pre><code class="hljs css language-sql"><span class="hljs-keyword">SELECT</span> elements, 
transform(elements, v -&gt; v * <span class="hljs-number">2</span>) <span class="hljs-keyword">as</span> multiplied_elements
<span class="hljs-keyword">FROM</span> (
    <span class="hljs-keyword">VALUES</span>
        (<span class="hljs-built_in">ARRAY</span>[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]),
        (<span class="hljs-built_in">ARRAY</span>[<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>]),
        (<span class="hljs-built_in">ARRAY</span>[<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">16</span>, <span class="hljs-number">64</span>])
) <span class="hljs-keyword">AS</span> t(elements)
</code></pre>
<p>In Presto, a lambda expression consists of an argument list and lambda body, separated by <code>-&gt;</code>:</p>
<pre><code class="hljs css language-sql">x -&gt; x + 1
(x, y) -&gt; x + y
x -&gt; regexp_like(x, 'a+')
x -&gt; x[1] / x[2]
x -&gt; IF(x &gt; 0, x, -x)
x -&gt; COALESCE(x, 0)
x -&gt; CAST(x AS JSON)
x -&gt; x + TRY(1 / 0)
</code></pre>
<p>Note there is no type annotation in a lambda expression. The type of a lambda expression (e.g. <code>function(integer, integer)</code>) thus has to be inferred from the context of function call. As a result, standalone lambda expressions are not allowed since their types cannot be determined.</p>
]]></summary>
        <author>
            <name>Wenlei Xie</name>
            <uri>https://www.linkedin.com/in/wenleix/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Announcing PrestoCon 2020: Advancing the Big Data Ecosystem with Presto]]></title>
        <id>https://prestodb.io/blog/2020/02/13/prestocon-announcement.html</id>
        <link href="https://prestodb.io/blog/2020/02/13/prestocon-announcement.html"/>
        <updated>2020-02-13T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>On March 24, 2020 in San Mateo, the Presto Foundation, in partnership with The Linux Foundation, will be hosting the organization’s first-ever <a href="https://events.linuxfoundation.org/prestocon/">PrestoCon</a>. The event, one of the first Presto-focused full-day conferences ever held, will feature speakers...</p>]]></summary>
        <author>
            <name>Nezih Yigitbasi</name>
            <uri>https://www.linkedin.com/in/nezihyigitbasi/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Improving the Presto planner for better push down and data federation]]></title>
        <id>https://prestodb.io/blog/2019/12/23/improve-presto-planner.html</id>
        <link href="https://prestodb.io/blog/2019/12/23/improve-presto-planner.html"/>
        <updated>2019-12-23T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p><strong>Alibaba:</strong> Yuan Mei</p>
<p><strong>Facebook:</strong> James Sun, Maria Basmanova, Rongrong Zhong, Jiexi Lin, Saksham Sachdev</p>
<p><strong>Pinterest:</strong> Yi He</p>
<p><strong>University of Waterloo:</strong> Akshay Pall</p>
<p>Presto defines a connector API that allows Presto to query any data source that has a connector implementation. The existing connector API provides basic predicate pushdown functionality allowing connectors to perform filtering at the underlying data source.</p>
<p>However, there are certain limitations with the existing predicate pushdown functionality that limits what connectors can do. The expressiveness of what can be pushed down is limited and the connectors can't change the structure of the plan at all.</p>
]]></summary>
        <author>
            <name>Yi He</name>
            <uri>https://www.linkedin.com/in/yi-he-69aa9723/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[5 design choices—and 1 weird trick — to get 2x efficiency gains in Presto repartitioning]]></title>
        <id>https://prestodb.io/blog/2019/12/20/repartition.html</id>
        <link href="https://prestodb.io/blog/2019/12/20/repartition.html"/>
        <updated>2019-12-20T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Ying Su, Masha Basmanova, Orri Erling, Tim Meehan, Sahar Massachi, Bhavani Hari</p>
<p>We like Presto. We like it a lot — so much we want to make it better in every way. Here's an example: we just optimized the PartitionedOutputOperator. It's now 2-3x more CPU efficient, which, when measured against Facebook's production workload, translates to 6% gains overall. That's huge.</p>
<p>The optimized repartitioning is in use on some production Presto clusters right now, and available for use as of release 0.229.</p>
<p>In this note, let's go over how we did it, what optimizations we unlocked specifically, and a case study of how we approached opportunity sizing whether this was worth doing at all.</p>
]]></summary>
        <author>
            <name>Ying Su</name>
            <uri>https://www.linkedin.com/in/ying-su-b00b81107/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Join Us! Growing the Presto Foundation in 2020 and Beyond]]></title>
        <id>https://prestodb.io/blog/2019/12/16/growing-the-presto-foundation.html</id>
        <link href="https://prestodb.io/blog/2019/12/16/growing-the-presto-foundation.html"/>
        <updated>2019-12-16T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>The Presto Foundation (PF) was <a href="https://www.linuxfoundation.org/press-release/2019/09/facebook-uber-twitter-and-alibaba-form-presto-foundation-to-tackle-distributed-data-processing-at-scale/">established in September 2019</a> as an openly governed and vendor-neutral body dedicated to scaling and diversifying the <a href="https://prestodb.io/">Presto</a> community. Hosted by the Linux Foundation, PF and its Governing Board are in a unique position...</p>]]></summary>
        <author>
            <name>Brian Hsieh</name>
            <uri>https://www.linkedin.com/in/briankhsieh/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Table Scan: Doing The Right Thing With Structured Types]]></title>
        <id>https://prestodb.io/blog/2019/09/26/tablescan-structs.html</id>
        <link href="https://prestodb.io/blog/2019/09/26/tablescan-structs.html"/>
        <updated>2019-09-26T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>In the previous article we saw what gains are possible when filtering early and in the right order. In this article we look at how we do this with nested and structured types.</p>
]]></summary>
        <author>
            <name>Orri Erling</name>
            <uri>https://www.linkedin.com/in/orrierling/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Presto now hosted under the Linux Foundation]]></title>
        <id>https://prestodb.io/blog/2019/09/23/linux-foundation.html</id>
        <link href="https://prestodb.io/blog/2019/09/23/linux-foundation.html"/>
        <updated>2019-09-23T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>We are excited to announce today, in partnership with <a href="https://www.alibaba.com/">Alibaba</a>, <a href="https://www.facebook.com/">Facebook</a>, <a href="https://twitter.com/home">Twitter</a>, and <a href="https://www.uber.com">Uber</a>, the launch of the Presto Foundation, a non-profit organization under the umbrella of the <a href="https://www.linuxfoundation.org/">Linux Foundation</a>.</p> <p>Hosting by the Linux Foundation opens up the Presto...</p>]]></summary>
        <author>
            <name>Ariel Weisberg</name>
            <uri>https://www.linkedin.com/in/ariel-weisberg-a5b6899</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memory Management in Presto]]></title>
        <id>https://prestodb.io/blog/2019/08/19/memory-tracking.html</id>
        <link href="https://prestodb.io/blog/2019/08/19/memory-tracking.html"/>
        <updated>2019-08-19T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>In a multi-tenant system like Presto careful memory management is required to keep the system stable and prevent individual queries from taking over all the resources. However, tracking the memory usage of data structures in an application (Presto) running on the Java Virtual Machine (JVM) requires a significant amount of work. In addition, Presto is a distributed system, which makes the problem more complicated. This post provides an overview of how memory management works in Presto, and provides info about the various memory management related JMX counters/endpoints that can be used for monitoring production clusters.</p>
]]></summary>
        <author>
            <name>Nezih Yigitbasi</name>
            <uri>https://www.linkedin.com/in/nezihyigitbasi/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Presto Unlimited: MPP SQL Engine at Scale]]></title>
        <id>https://prestodb.io/blog/2019/08/05/presto-unlimited-mpp-database-at-scale.html</id>
        <link href="https://prestodb.io/blog/2019/08/05/presto-unlimited-mpp-database-at-scale.html"/>
        <updated>2019-08-05T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Wenlei Xie, Andrii Rosa, Shixuan Fan, Rebecca Schlussel, Tim Meehan</p>
<p>Presto is an open source distributed SQL query engine for running analytic queries against data sources of all sizes ranging from gigabytes to petabytes.</p>
<p>Presto was originally designed for interactive use cases, however, after seeing the merit in having a single interface for both batch and interactive, it is now also used heavily for processing batch workloads [6]. As a concrete example, more than 80% of new warehouse batch workloads at Facebook are developed on Presto. Its flexible “connector” design makes it possible to run queries against heterogeneous data sources — such as joining together Hive and MySQL tables without preloading the data.</p>
<p>However, memory-intensive (many TBs) and long-running (multiple hours) queries have been major pain points for Presto users. It is difficult to reason how much memory queries will use and when it will hit memory limit, and failures in long-running queries cause retries which create landing time variance. To improve user experience and scale MPP Database to large ETL workloads, we started this Presto Unlimited project.</p>
]]></summary>
        <author>
            <name>Wenlei Xie</name>
            <uri>https://www.linkedin.com/in/wenleix/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complete Table Scan: A Quantitative Assessment]]></title>
        <id>https://prestodb.io/blog/2019/07/23/complete-table-scan.html</id>
        <link href="https://prestodb.io/blog/2019/07/23/complete-table-scan.html"/>
        <updated>2019-07-23T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>In the previous article we looked at the abstract problem statement and possibilities inherent in scanning tables. In this piece we look at the quantitative upside with Presto. We look at a number of queries and explain the findings.</p>
<p>The initial impulse motivating this work is the observation that table scan is by far the #1 operator in Presto workloads I have seen. This is a little over half of all Presto CPU, with repartitioning a distant second, at around 1/10 of the total. The other half of the motivation is ready opportunity: Presto in its pre-Aria state does almost none of the things that are common in table scan.</p>
]]></summary>
        <author>
            <name>Orri Erling</name>
            <uri>https://www.linkedin.com/in/orrierling/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Everything You Always Wanted To Do in Table Scan]]></title>
        <id>https://prestodb.io/blog/2019/06/29/everything-you-always-wanted-to-do-in-a-table-scan.html</id>
        <link href="https://prestodb.io/blog/2019/06/29/everything-you-always-wanted-to-do-in-a-table-scan.html"/>
        <updated>2019-06-29T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Orri Erling, Maria Basmanova, Ying Su, Timothy Meehan, Elon Azoulay</p>
<p>Table scan, on the face of it, sounds trivial and boring. What’s there in just reading a long bunch of records from first to last? Aren’t indexing and other kinds of physical design more interesting?</p>
<p>As data has gotten bigger, the columnar table scan has only gotten more prominent. The columnar scan is a fairly safe baseline operation: The cost of writing data is low, the cost of reading it is predictable.</p>
<p>Another factor that makes the table scan the main operation is the omnipresent denormalization in data warehouse. This only goes further as a result of ubiquitous use of lists and maps and other non-first normal form data.</p>
<p>The aim of this series of articles is to lay out the full theory and practice of table scan with all angles covered. We will see that this is mostly a matter of common sense and systematic application of a few principles: Do not do extra work and do the work that you do always in bulk. Many systems like Google’s BigQuery do some subset of the optimizations outlined here. Doing all of these is however far from universal in the big data world, so there is a point in laying this all out and making a model implementation on top of Presto. We are here talking about the ORC format, but the same things apply equally to Parquet or JSON shredded into columns.</p>
]]></summary>
        <author>
            <name>Orri Erling</name>
            <uri>https://www.linkedin.com/in/orrierling/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing the Presto blog]]></title>
        <id>https://prestodb.io/blog/2019/06/28/introducing-the-presto-blog.html</id>
        <link href="https://prestodb.io/blog/2019/06/28/introducing-the-presto-blog.html"/>
        <updated>2019-06-28T06:00:00.000Z</updated>
        <summary type="html"><![CDATA[<p>Presto is a key piece of data infrastructure at many companies. The community has many ongoing projects for taking it to new levels of performance and functionality plus unique experience and insight into challenges of scale.</p> <p>We are opening this blog...</p>]]></summary>
        <author>
            <name>Orri Erling</name>
            <uri>https://www.linkedin.com/in/orrierling/</uri>
        </author>
    </entry>
</feed>