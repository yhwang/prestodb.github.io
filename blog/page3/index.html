<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Blog · </title><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Fast and Reliable SQL for Data Analytics and the Open Lakehouse"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Blog · "/><meta property="og:type" content="website"/><meta property="og:url" content="https://yhwang.github.io/prestodb.github.io//"/><meta property="og:description" content="Fast and Reliable SQL for Data Analytics and the Open Lakehouse"/><meta property="og:image" content="https://yhwang.github.io/prestodb.github.io/img/presto-logo-stacked.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://yhwang.github.io/prestodb.github.io/img/presto-logo-stacked.png"/><link rel="shortcut icon" href="/img/icon-presto-dots-color.svg"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="stylesheet" href="/css/bootstrap.min.css"/><link rel="stylesheet" href="/css/custom.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://js.hs-scripts.com/39785153.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="blog"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/logo-presto-white.svg" alt=""/><h2 class="headerTitleWithLogo"></h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/getting-started.html" target="_self">Get Started</a></li><li class=""><a href="/what-is-presto.html" target="_self">Learn</a></li><li class=""><a href="/community.html" target="_self">Community</a></li><li class=""><a href="/blog" target="_self">Blog</a></li><li class=""><a href="/docs/current" target="_blank">Docs</a></li><li class=""><a href="https://communityinviter.com/apps/prestodb/prestodb" target="_blank">Slack</a></li><li class=""><a href="https://github.com/prestodb/presto" target="_blank">GitHub</a></li><li class=""><a href="https://stackoverflow.com/questions/tagged/presto" target="_blank">Stackoverflow</a></li><li class=""><a href="https://twitter.com/prestodb" target="_blank">Twitter</a></li><li class=""><a href="https://www.linkedin.com/company/presto-foundation/" target="_blank">LinkedIn</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Recent Posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Recent Posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/blog/2023/08/29/presto-working-groups">Introducing Presto Working Groups</a></li><li class="navListItem"><a class="navItem" href="/blog/2023/08/17/scaling-presto-panel-blog">Scaling Presto for Data Analytics - Insights from Meta, Uber, and Intuit</a></li><li class="navListItem"><a class="navItem" href="/blog/2023/08/02/presto-on-kubernetes-with-helm-prestocon-day">Simplifying Presto on Kubernetes - Introducing the Presto Helm Chart</a></li><li class="navListItem"><a class="navItem" href="/blog/2023/07/20/quick-stats-presto-blog">Quick Stats - Runtime ANALYZE for Better Query Plans with Presto</a></li><li class="navListItem"><a class="navItem" href="/blog/2023/07/13/presto-at-bolt">Migrating to Presto - How Bolt Built a Data Platform Architecture for Scalability and Cost Efficiency</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="posts"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2022/04/15/disggregated-coordinator">Disaggregated Coordinator</a></h1><p class="post-meta">April 15, 2022</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/swapnil-tailor-23077b6/" target="_blank" rel="noreferrer noopener">Swapnil Tailor</a></p></div></header><article class="post-content"><div><span><p><strong>Meta</strong>: Swapnil Tailor, Tim Meehan, Vaishnavi Batni, Abhisek Saikia, Neerad Somanchi</p>
<h2><a class="anchor" aria-hidden="true" id="overview"></a><a href="#overview" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p>Presto's architecture originally only supported a single coordinator and a pool of workers. This has worked well for many years but created some challenges.</p>
<ul>
<li>With a single coordinator, the cluster can scale up to a certain number of workers reliably. A large worker pool running complex, multi-stage queries can overwhelm an inadequately provisioned coordinator, requiring upgraded hardware to support the increase in worker load.</li>
<li>A single coordinator is a single point of failure for the Presto cluster.</li>
</ul>
<p>To overcome these challenges, we came up with a new design with a disaggregated coordinator that allows the coordinator to be horizontally scaled out across a single pool of workers.</p>
</span></div><div class="read-more"><a class="button" href="/blog/2022/04/15/disggregated-coordinator">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2022/03/15/native-delta-lake-connector-for-presto">Native Delta Lake Connector for Presto</a></h1><p class="post-meta">March 15, 2022</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/pednero" target="_blank" rel="noreferrer noopener">Rohan Pednekar</a></p></div></header><article class="post-content"><div><span><p><strong>Co-authors</strong><br>
<a href="https://www.linkedin.com/in/dennyglee/">Denny Lee</a>, Sr. Staff Developer Advocate at Databricks</p>
<p>This is a joint publication by the PrestoDB and Delta Lake communities</p>
<p><img src="/img/blog/2022-03-15-native-delta-lake-connector-for-presto/banner.png" alt="Native Delta Lake Connector for Presto"></p>
<p>Due to the popularity of both the <a href="https://prestodb.io">PrestoDB</a> and <a href="https://delta.io">Delta Lake</a> projects (more on this below), in <a href="https://databricks.com/blog/2020/01/29/query-delta-lake-tables-presto-athena-improved-operations-concurrency-merge-performance.html">early 2020</a> the Delta Lake community announced that one could query Delta tables from PrestoDB. While popular, this method entailed the use of a manifest file where a Delta table is registered in Hive metastore as symlink table type. While this approach may satisfy batch processing requirements, it did not satisfy frequent processing or streaming requirements.  Therefore, we are happy to announce the release of the native Delta Lake connector for PrestoDB (<a href="https://github.com/prestodb/presto/tree/master/presto-delta">source code</a> | <a href="https://prestodb.io/docs/current/connector/deltalake.html">docs</a>).</p>
</span></div><div class="read-more"><a class="button" href="/blog/2022/03/15/native-delta-lake-connector-for-presto">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2022/01/28/avoid-data-silos-in-presto-in-meta">Avoid Data Silos in Presto in Meta: the journey from Raptor to RaptorX</a></h1><p class="post-meta">January 28, 2022</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/rongrong-zhong-31aa8a8/" target="_blank" rel="noreferrer noopener">Rongrong Zhong</a></p></div></header><article class="post-content"><div><span><p><strong>Alluxio</strong>: Rongrong Zhong
<strong>Meta</strong>: James Sun, Ke Wang</p>
<p><em>Raptor</em> is a Presto connector (<a href="https://github.com/prestodb/presto/tree/master/presto-raptor">presto-raptor</a>) that is used to power some critical
interactive query workloads in Meta (previously Facebook). Though referred to in the ICDE 2019 paper
<em><a href="https://research.facebook.com/publications/presto-sql-on-everything/">Presto: SQL on Everything</a></em>, it remains somewhat mysterious to many
Presto users because there is no available documentation for this feature. This article will shed some light on the history of Raptor, and why
Meta eventually replaced it in favor of a new architecture based on local caching, namely RaptorX.</p>
<p><img src="/img/blog/2022-01-28-avoid-data-silos-in-presto-in-meta/timeline.png" alt="Raptor Timeline"></p>
<h2><a class="anchor" aria-hidden="true" id="the-story-of-raptor"></a><a href="#the-story-of-raptor" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The story of Raptor</h2>
<p>Generally speaking, Presto as a query engine does not own storage. Instead, connectors were developed to query different external data sources.
This framework is very flexible, but in disaggregated compute and storage architectures it is hard to offer low latency guarantees. Network and
storage latency add difficult to avoid variability. To address this limitation, Raptor was designed as a shared-nothing storage engine for Presto.</p>
<h3><a class="anchor" aria-hidden="true" id="motivation--an-initial-use-case-in-the-ab-testing-framework"></a><a href="#motivation--an-initial-use-case-in-the-ab-testing-framework" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Motivation – an initial use case in the AB testing framework</h3>
</span></div><div class="read-more"><a class="button" href="/blog/2022/01/28/avoid-data-silos-in-presto-in-meta">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/11/22/common-sub-expression-optimization">Common Sub-Expression optimization</a></h1><p class="post-meta">November 22, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/rongrong-zhong-31aa8a8/" target="_blank" rel="noreferrer noopener">Rongrong Zhong</a></p></div></header><article class="post-content"><div><span><h2><a class="anchor" aria-hidden="true" id="the-problem"></a><a href="#the-problem" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The problem</h2>
<p>One common pattern we see in some analytical workloads is the repeated use of the same, often times expensive expression. Look at the following query plan for example:</p>
<p><img src="/img/blog/2021-11-22-common-sub-expression-optimization/query-plan.png" alt="Query Plan"></p>
<p>The expression <code>JSON_PARSE(features)</code> is used 6 times, and casted to different <code>ROW</code> structures for further processing. Traditionally, Presto would just execute the expression 6 times, in 6 separate projections. Since Presto would generate efficient bytecode for each projection, this would not be a problem as long as the expression itself is not expensive. For example, executing <code>x+y</code> 6 times in a cache efficient way would not necessarily incur a big performance overhead. However, running expensive string manipulations like <code>JSON_PARSE</code> or <code>REGEX</code> operations multiple times could quickly add up.</p>
</span></div><div class="read-more"><a class="button" href="/blog/2021/11/22/common-sub-expression-optimization">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/10/26/Scaling-with-Presto-on-Spark">Scaling with Presto on Spark</a></h1><p class="post-meta">October 26, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/pednero" target="_blank" rel="noreferrer noopener">Rohan Pednekar</a></p></div></header><article class="post-content"><div><span><p><strong>Co-authors</strong><br>
<a href="https://www.linkedin.com/in/shradha-ambekar-a0504714">Shradha Ambekar</a>, Staff Software Engineer at <a href="https://www.intuit.com/">Intuit</a><br>
<a href="https://www.linkedin.com/in/ariel-weisberg-a5b6899">Ariel Weisberg</a>, Software Engineer at <a href="https://www.facebook.com/">Facebook</a></p>
<h2><a class="anchor" aria-hidden="true" id="overview"></a><a href="#overview" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p>Presto was originally designed to run interactive queries against data warehouses, but now it has evolved into a unified SQL engine on top of open data lake analytics for both interactive and batch workloads. Popular workloads on data lakes include:</p>
<h3><a class="anchor" aria-hidden="true" id="1-reporting-and-dashboarding"></a><a href="#1-reporting-and-dashboarding" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1. Reporting and dashboarding</h3>
<p>This includes serving custom reporting for both internal and external developers for business insights and also many organizations using Presto for interactive A/B testing analytics. A defining characteristic of this use case is a requirement for low latency. It requires tens to hundreds of milliseconds at very high QPS, and not surprisingly this use case is almost exclusively using Presto and that's what Presto is designed for.</p>
<h3><a class="anchor" aria-hidden="true" id="2-data-science-with-sql-notebooks"></a><a href="#2-data-science-with-sql-notebooks" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2. Data science with SQL notebooks</h3>
<p>This use case is one of ad hoc analysis and typically needs moderate latency ranging from seconds to minutes. These are the queries of data scientist, and business analysts who want to perform compact ad hoc analysis to understand product usage, for example, user trends and how to improve the product. The QPS is relatively lower because users have to manually initiate these queries.</p>
<h3><a class="anchor" aria-hidden="true" id="3-batch-processing-for-large-data-pipelines"></a><a href="#3-batch-processing-for-large-data-pipelines" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3. Batch processing for large data pipelines</h3>
<p>These are scheduled jobs that are running every day, hour, or whenever the data is ready. They often contain queries over very large volumes of data and the latency can be up to tens of hours and processing can range from CPU days to years and terabytes to petabytes of data.</p>
<p>Presto works exceptionally effectively for ad-hoc or interactive queries today, and even some batch queries, with the constraint that the entire query must fit in memory and run quickly enough that fault tolerance is not required. Most ETL batch workloads that don’t fit in this box are running on “very big data” compute engines like Apache Spark. Having multiple compute engines with different SQL dialects and APIs makes managing and scaling these workloads complicated for data platform teams. Hence, Facebook decided to simplify and build Presto on Spark as the path to further scale Presto. Before we get into Presto on Spark, let me explain a bit more about the architecture of each of these two popular engines.</p>
</span></div><div class="read-more"><a class="button" href="/blog/2021/10/26/Scaling-with-Presto-on-Spark">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/06/29/native-parquet-writer-for-presto">Native Parquet Writer for Presto</a></h1><p class="post-meta">June 29, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/luniu/" target="_blank" rel="noreferrer noopener">Lu Niu</a></p></div></header><article class="post-content"><div><span><p><strong>Pinterest:</strong> Lu Niu</p>
<p><strong>Twitter:</strong> Zhenxiao Luo</p>
<h2><a class="anchor" aria-hidden="true" id="overview"></a><a href="#overview" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Overview</h2>
<p>With the wide deployment of Presto in a growing number of companies, Presto is used not only for queries, but also for data ingestion and ETL jobs. There is a need to improve Presto’s file writer performance, especially for popular columnar file formats, e.g. Parquet, and ORC. In this article, we introduce the brand new native Parquet writer for Presto, which writes directly from Presto's columnar data structure to Parquet's columnar values, with up to 6X throughput improvement and less CPU and memory overhead.</p>
</span></div><div class="read-more"><a class="button" href="/blog/2021/06/29/native-parquet-writer-for-presto">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/06/14/Commitment-to-Presto-Open-Source-Community">Presto Foundation and PrestoDB: Our Commitment to the Presto Open Source Community</a></h1><p class="post-meta">June 14, 2021</p><div class="authorBlock"><p class="post-authorName"><a target="_blank" rel="noreferrer noopener">Girish Baliga, Tim Meehan, Dipti Borkar, Amit Chopra, Zhenxiao Luo, Arijit Bandyopadhyay, Steven Mih, Bin Fan</a></p></div></header><article class="post-content"><div><span><p><strong>Authors</strong></p>
<ul>
<li>Girish Baliga, Chair, Presto Foundation, Presto Foundation Member: <a href="https://www.uber.com/">Uber</a></li>
<li>Tim Meehan, Chair, Presto Foundation, Technical Steering Committee, Presto Foundation Member: <a href="https://www.facebook.com/">Facebook</a></li>
<li>Dipti Borkar, Chair, Presto Foundation, Outreach, Presto Foundation Member: <a href="https://ahana.io/">Ahana</a></li>
<li>Amit Chopra, Board member, Presto Foundation Member: <a href="https://www.facebook.com/">Facebook</a></li>
<li>Zhenxiao Luo , Board member, Presto Foundation Member: <a href="https://twitter.com/">Twitter</a></li>
<li>Arijit Bandyopadhyay, Board member, Presto Foundation Member: <a href="https://intel.com/">Intel</a></li>
<li>Steven Mih, Board member, Presto Foundation Member: <a href="https://ahana.io/">Ahana</a></li>
<li>Bin Fan, Outreach team member, Presto Foundation Member: <a href="https://www.alluxio.io/">Alluxio</a></li>
</ul>
<p>We recently wrapped up an amazing PrestoCon Day attended by over 600 people from across the globe. The technical discussions and the panel was a clear indication of the growing community. We showcased a number of features contributed by various companies that continue to advance the mission of Presto open source, reiterating our commitment to grow the Presto community and support the continued improvement of the core technology.</p>
</span></div><div class="read-more"><a class="button" href="/blog/2021/06/14/Commitment-to-Presto-Open-Source-Community">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/02/04/raptorx">RaptorX: Building a 10X Faster Presto</a></h1><p class="post-meta">February 4, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/yutiansun/" target="_blank" rel="noreferrer noopener">James Sun</a></p><div class="authorPhoto"><a href="https://www.linkedin.com/in/yutiansun/" target="_blank" rel="noreferrer noopener"><img src="https://graph.facebook.com/100001087056694/picture/?height=200&amp;width=200" alt="James Sun"/></a></div></div></header><article class="post-content"><div><span><div style="text-align: justify">
<p><strong>Facebook:</strong> Abhinav Sharma, Amit Dutta, Baldeep Hira, Biswapesh Chattopadhyay, James Sun, Jialiang Tan, Ke Wang, Lin Liu, Naveen Cherukuri, Nikhil Collooru, Peter Na, Prashant Nema, Rohit Jain, Saksham Sachdev, Sergey Pershin, Shixuan Fan, Varun Gajjala</p>
<p><strong>Alluxio:</strong> Bin Fan, Calvin Jia, Haoyuan Li</p>
<p><strong>Twitter:</strong> Zhenxiao Luo</p>
<p><strong>Pinterest:</strong> Lu Niu</p>
<p><em>RaptorX is an internal project name aiming to boost query latency significantly beyond what vanilla Presto is capable of. This blog post introduces the hierarchical cache work, which is the key building block for RaptorX. With the support of the cache, we are able to boost query performance by 10X. This new architecture can beat performance oriented connectors like Raptor with the added benefit of continuing to work with disaggregated storage.</em></p>
</span></div><div class="read-more"><a class="button" href="/blog/2021/02/04/raptorx">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2021/01/12/2020-recap-year-with-presto">2020 Recap - A Year with Presto</a></h1><p class="post-meta">January 12, 2021</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/diptiborkar/" target="_blank" rel="noreferrer noopener">Dipti Borkar</a></p></div></header><article class="post-content"><div><span><p>Tl;dr: 2020 was a huge year for the Presto community. We held our first major conference, PrestoCon, the biggest Presto event ever. We had a massive expansion of our meetup groups with more than 20 sessions held throughout the year, and significant innovations were contributed to Presto!</p>
<p>This year has certainly been unique, to say the least. As chairperson of the Presto Foundation Outreach Committee, the term “outreach” took on a whole new meaning this year. But through the challenges of 2020, we adopted new ways to connect. We continued to build and engage with the Presto community in a new “virtual” way, and I couldn’t be more proud of all we’ve accomplished as a community in 2020.</p>
<p>So what did the Presto Foundation do in 2020?</p>
</span></div><div class="read-more"><a class="button" href="/blog/2021/01/12/2020-recap-year-with-presto">Read More</a></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/12/04/typedset">Using OptimizedTypedSet to Improve Map and Array Functions</a></h1><p class="post-meta">December 4, 2020</p><div class="authorBlock"><p class="post-authorName"><a href="https://www.linkedin.com/in/ying-su-b00b81107/" target="_blank" rel="noreferrer noopener">Ying Su</a></p><div class="authorPhoto"><a href="https://www.linkedin.com/in/ying-su-b00b81107/" target="_blank" rel="noreferrer noopener"><img src="https://graph.facebook.com/656599427/picture/?height=200&amp;width=200" alt="Ying Su"/></a></div></div></header><article class="post-content"><div><span><p>Function evaluation is a big part of projection CPU cost. Recently we optimized a set of functions that use <code>TypedSet</code>, e.g.  <code>map_concat</code>, <code>array_union</code>, <code>array_intersect</code>, and <code>array_except</code>. By introducing a new <code>OptimizedTypeSet</code>, the above functions saw improvements in several dimensions:</p>
<ul>
<li>Up to 80% reduction in wall time and CPU time in JMH benchmarks</li>
<li>Reserved memory reduced by 5%</li>
<li>Allocation rate reduced by 80%</li>
</ul>
<p>Furthermore, OptimizedTypeSet resolves the long standing issue of throwing <code>EXCEEDED_FUNCTION_MEMORY_LIMIT</code> for large incoming blocks: &quot;The input to function_name is too large. More than 4MB of memory is needed to hold the intermediate hash set.”</p>
<p>The <code>OptimizedTypeSet</code> and improvements to the above mentioned functions are merged to master, and will be available from Presto 0.244.</p>
</span></div><div class="read-more"><a class="button" href="/blog/2020/12/04/typedset">Read More</a></div></article></div><div class="docs-prevnext"><a class="docs-prev" href="/blog/page2/">← Prev</a><a class="docs-next" href="/blog/page4/">Next →</a></div></div></div></div></div><footer class="nav-footer" id="footer"><section class="copyright">Copyright © The Presto Foundation.<br/>All rights reserved. Presto is a registered trademark of LF Projects, LLC. <br/>Please see our<a href="https://lfprojects.org/policies/trademark-policy/">Trademark Policy</a> for more information.<br/><a href="https://lfprojects.org/policies/privacy-policy/">Privacy Policy</a> |<a href="https://lfprojects.org/policies/terms-of-use/">Terms of Use</a>.</section></footer></div></body></html>